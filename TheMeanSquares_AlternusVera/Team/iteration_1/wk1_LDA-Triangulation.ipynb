{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LDA-Triangulation.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"dUXeKYwiQqXD","colab_type":"code","outputId":"4c495eca-3706-4f7c-cd70-7af7f07975e6","executionInfo":{"status":"ok","timestamp":1587146121750,"user_tz":420,"elapsed":2411,"user":{"displayName":"Subarna Chowdhury Soma","photoUrl":"","userId":"13997249864171991230"}},"colab":{"base_uri":"https://localhost:8080/","height":154}},"source":["import pandas as pd\n","import numpy as np\n","import csv\n","import os\n","import gensim\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report\n","from sklearn.preprocessing import StandardScaler\n","from nltk.stem.wordnet import WordNetLemmatizer\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import confusion_matrix\n","from nltk.stem.porter import PorterStemmer\n","from sklearn import metrics\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import roc_curve\n","from sklearn.pipeline import Pipeline\n","from nltk.corpus import stopwords\n","from string import punctuation\n","import seaborn as sns\n","import pandas as pd\n","import numpy as np\n","import nltk\n","import re\n","import nltk\n","\n","from nltk.stem.porter import PorterStemmer\n","import time\n","from nltk import FreqDist\n","from scipy.stats import entropy\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set_style(\"darkgrid\")\n","\n","nltk.download('stopwords')\n","nltk.download('averaged_perceptron_tagger')\n","from scipy import sparse\n","\n","\n","import matplotlib.pyplot as mp\n","%matplotlib inline\n","# Code source: https://degravek.github.io/project-pages/project1/2017/04/28/New-Notebook/\n","# Dataset from Chakraborty et al. (https://github.com/bhargaviparanjape/clickbait/tree/master/dataset)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"},{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KJ58vQN9QxQX","colab_type":"text"},"source":["# Mount Data from Google Drive"]},{"cell_type":"code","metadata":{"id":"Z48w4vpAQ0NR","colab_type":"code","colab":{}},"source":["os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"2\"\n","import warnings; warnings.simplefilter('ignore')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jWI7if1XQ2jo","colab_type":"code","outputId":"e5eeafd6-ca22-4f96-ba59-bad00f3b5a1e","executionInfo":{"status":"ok","timestamp":1587146149051,"user_tz":420,"elapsed":29665,"user":{"displayName":"Subarna Chowdhury Soma","photoUrl":"","userId":"13997249864171991230"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vinSHgzhRKDk","colab_type":"text"},"source":["# Loading Kaggle dataset \n","https://www.kaggle.com/mrisdal/fake-news\n"]},{"cell_type":"code","metadata":{"id":"xkAMe_SIQ7rG","colab_type":"code","outputId":"c2033d1c-bc37-465d-9b3f-e5a014a0ca8f","executionInfo":{"status":"ok","timestamp":1587146153412,"user_tz":420,"elapsed":34017,"user":{"displayName":"Subarna Chowdhury Soma","photoUrl":"","userId":"13997249864171991230"}},"colab":{"base_uri":"https://localhost:8080/","height":568}},"source":["fake_data = pd.read_csv('/content/drive/Shared drives/CMPE 257: Machine Learning/AlterusVera-Datasets/fake.csv', low_memory =False, encoding = \"ISO-8859-1\")\n","fake_data.head(5)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>uuid</th>\n","      <th>ord_in_thread</th>\n","      <th>author</th>\n","      <th>published</th>\n","      <th>title</th>\n","      <th>text</th>\n","      <th>language</th>\n","      <th>crawled</th>\n","      <th>site_url</th>\n","      <th>country</th>\n","      <th>domain_rank</th>\n","      <th>thread_title</th>\n","      <th>spam_score</th>\n","      <th>main_img_url</th>\n","      <th>replies_count</th>\n","      <th>participants_count</th>\n","      <th>likes</th>\n","      <th>comments</th>\n","      <th>shares</th>\n","      <th>type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6a175f46bcd24d39b3e962ad0f29936721db70db</td>\n","      <td>0</td>\n","      <td>Barracuda Brigade</td>\n","      <td>2016-10-26T21:41:00.000+03:00</td>\n","      <td>Muslims BUSTED: They Stole Millions In Govât...</td>\n","      <td>Print They should pay all the back all the mon...</td>\n","      <td>english</td>\n","      <td>2016-10-27T01:49:27.168+03:00</td>\n","      <td>100percentfedup.com</td>\n","      <td>US</td>\n","      <td>25689.0</td>\n","      <td>Muslims BUSTED: They Stole Millions In Govât...</td>\n","      <td>0.000</td>\n","      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>bias</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2bdc29d12605ef9cf3f09f9875040a7113be5d5b</td>\n","      <td>0</td>\n","      <td>reasoning with facts</td>\n","      <td>2016-10-29T08:47:11.259+03:00</td>\n","      <td>Re: Why Did Attorney General Loretta Lynch Ple...</td>\n","      <td>Why Did Attorney General Loretta Lynch Plead T...</td>\n","      <td>english</td>\n","      <td>2016-10-29T08:47:11.259+03:00</td>\n","      <td>100percentfedup.com</td>\n","      <td>US</td>\n","      <td>25689.0</td>\n","      <td>Re: Why Did Attorney General Loretta Lynch Ple...</td>\n","      <td>0.000</td>\n","      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>bias</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>c70e149fdd53de5e61c29281100b9de0ed268bc3</td>\n","      <td>0</td>\n","      <td>Barracuda Brigade</td>\n","      <td>2016-10-31T01:41:49.479+02:00</td>\n","      <td>BREAKING: Weiner Cooperating With FBI On Hilla...</td>\n","      <td>Red State : \\nFox News Sunday reported this mo...</td>\n","      <td>english</td>\n","      <td>2016-10-31T01:41:49.479+02:00</td>\n","      <td>100percentfedup.com</td>\n","      <td>US</td>\n","      <td>25689.0</td>\n","      <td>BREAKING: Weiner Cooperating With FBI On Hilla...</td>\n","      <td>0.000</td>\n","      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>bias</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7cf7c15731ac2a116dd7f629bd57ea468ed70284</td>\n","      <td>0</td>\n","      <td>Fed Up</td>\n","      <td>2016-11-01T05:22:00.000+02:00</td>\n","      <td>PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...</td>\n","      <td>Email Kayla Mueller was a prisoner and torture...</td>\n","      <td>english</td>\n","      <td>2016-11-01T15:46:26.304+02:00</td>\n","      <td>100percentfedup.com</td>\n","      <td>US</td>\n","      <td>25689.0</td>\n","      <td>PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...</td>\n","      <td>0.068</td>\n","      <td>http://100percentfedup.com/wp-content/uploads/...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>bias</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0206b54719c7e241ffe0ad4315b808290dbe6c0f</td>\n","      <td>0</td>\n","      <td>Fed Up</td>\n","      <td>2016-11-01T21:56:00.000+02:00</td>\n","      <td>FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...</td>\n","      <td>Email HEALTHCARE REFORM TO MAKE AMERICA GREAT ...</td>\n","      <td>english</td>\n","      <td>2016-11-01T23:59:42.266+02:00</td>\n","      <td>100percentfedup.com</td>\n","      <td>US</td>\n","      <td>25689.0</td>\n","      <td>FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...</td>\n","      <td>0.865</td>\n","      <td>http://100percentfedup.com/wp-content/uploads/...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>bias</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                       uuid  ord_in_thread  ... shares  type\n","0  6a175f46bcd24d39b3e962ad0f29936721db70db              0  ...      0  bias\n","1  2bdc29d12605ef9cf3f09f9875040a7113be5d5b              0  ...      0  bias\n","2  c70e149fdd53de5e61c29281100b9de0ed268bc3              0  ...      0  bias\n","3  7cf7c15731ac2a116dd7f629bd57ea468ed70284              0  ...      0  bias\n","4  0206b54719c7e241ffe0ad4315b808290dbe6c0f              0  ...      0  bias\n","\n","[5 rows x 20 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"-jNUvQeZTNdU","colab_type":"text"},"source":["# Feature Engineering"]},{"cell_type":"markdown","metadata":{"id":"FHwDuRgORiBY","colab_type":"text"},"source":["## Define methods"]},{"cell_type":"code","metadata":{"id":"K_OKgNTlRN27","colab_type":"code","colab":{}},"source":["question_words = ['who', 'whos', 'whose', 'what', 'whats', 'whatre', 'when', 'whenre', 'whens', 'couldnt',\n","        'where', 'wheres', 'whered', 'why', 'whys', 'can', 'cant', 'could', 'will', 'would', 'is',\n","        'isnt', 'should', 'shouldnt', 'you', 'your', 'youre', 'youll', 'youd', 'here', 'heres',\n","        'how', 'hows', 'howd', 'this', 'are', 'arent', 'which', 'does', 'doesnt']\n","\n","contractions = ['tis', 'aint', 'amnt', 'arent', 'cant', 'couldve', 'couldnt', 'couldntve',\n","                'didnt', 'doesnt', 'dont', 'gonna', 'gotta', 'hadnt', 'hadntve', 'hasnt',\n","                'havent', 'hed', 'hednt', 'hedve', 'hell', 'hes', 'hesnt', 'howd', 'howll',\n","                'hows', 'id', 'idnt', 'idntve', 'idve', 'ill', 'im', 'ive', 'ivent', 'isnt',\n","                'itd', 'itdnt', 'itdntve', 'itdve', 'itll', 'its', 'itsnt', 'mightnt',\n","                'mightve', 'mustnt', 'mustntve', 'mustve', 'neednt', 'oclock', 'ol', 'oughtnt',\n","                'shant', 'shed', 'shednt', 'shedntve', 'shedve', 'shell', 'shes', 'shouldve',\n","                'shouldnt', 'shouldntve', 'somebodydve', 'somebodydntve', 'somebodys',\n","                'someoned', 'someonednt', 'someonedntve', 'someonedve', 'someonell', 'someones',\n","                'somethingd', 'somethingdnt', 'somethingdntve', 'somethingdve', 'somethingll',\n","                'somethings', 'thatll', 'thats', 'thatd', 'thered', 'therednt', 'theredntve',\n","                'theredve', 'therere', 'theres', 'theyd', 'theydnt', 'theydntve', 'theydve',\n","                'theydvent', 'theyll', 'theyontve', 'theyre', 'theyve', 'theyvent', 'wasnt',\n","                'wed', 'wedve', 'wednt', 'wedntve', 'well', 'wontve', 'were', 'weve', 'werent',\n","                'whatd', 'whatll', 'whatre', 'whats', 'whatve', 'whens', 'whered', 'wheres',\n","                'whereve', 'whod', 'whodve', 'wholl', 'whore', 'whos', 'whove', 'whyd', 'whyre',\n","                'whys', 'wont', 'wontve', 'wouldve', 'wouldnt', 'wouldntve', 'yall', 'yalldve',\n","                'yalldntve', 'yallll', 'yallont', 'yallllve', 'yallre', 'yallllvent', 'yaint',\n","                'youd', 'youdve', 'youll', 'youre', 'yourent', 'youve', 'youvent']\n","\n","def process_text(text):\n","    result = str(text).replace('/', '').replace('\\n', '')\n","    # result = re.sub(r'[1-9]+', 'number', result)\n","    # result = re.sub(r'(\\w)(\\1{2,})', r'\\1', result)\n","    # result = re.sub(r'(?x)\\b(?=\\w*\\d)\\w+\\s*', '', result)\n","    \n","    result = re.sub(\"((\\S+)?(http(s)?)(\\S+))|((\\S+)?(www)(\\S+))|((\\S+)?(\\@)(\\S+)?)\", \" \", result)\n","    result = re.sub(\"[^a-zA-Z ]\", \"\", result)\n","\n","    result = ''.join(t for t in result if t not in punctuation)\n","    result = re.sub(r' +', ' ', result).lower().strip()\n","    return result\n","\n","stop = stopwords.words('english')\n","stop.append('ð¾ñ')\n","def cnt_stop_words(text):\n","    s = text.split()\n","    num = len([word for word in s if word in stop])\n","    return num\n","\n","def num_contract(text):\n","    s = text.split()\n","    num = len([word for word in s if word in contractions])\n","    return num\n","\n","def question_word(text):\n","    s = text.split()\n","    if len(s) > 0 and s[0] in question_words:\n","        return 1\n","    else:\n","        return 0\n","\n","def part_of_speech(text):\n","    s = text.split()\n","    nonstop = [word for word in s if word not in stop]\n","    pos = [part[1] for part in nltk.pos_tag(nonstop)]\n","    pos = ' '.join(pos)\n","    return pos"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KqzVIfs_hJ61","colab_type":"text"},"source":["### Preprocessing "]},{"cell_type":"code","metadata":{"id":"gtCe8xzNhL_6","colab_type":"code","colab":{}},"source":["from nltk.tokenize import word_tokenize\n","\n","\n","def initial_clean(text):\n","    \"\"\"\n","    Function to clean text of websites, email addresess and any punctuation\n","    We also lower case the text\n","    \"\"\"\n","    text = re.sub(\"((\\S+)?(http(s)?)(\\S+))|((\\S+)?(www)(\\S+))|((\\S+)?(\\@)(\\S+)?)\", \" \", text)\n","    text = re.sub(\"[^a-zA-Z ]\", \"\", text)\n","    text = text.lower() # lower case the text\n","    text = text.split()\n","    return text\n","\n","stop_words = stopwords.words('english')\n","def remove_stop_words(text):\n","    \"\"\"\n","    Function that removes all stopwords from text\n","    \"\"\"\n","    return [word for word in text if word not in stop_words]\n","\n","stemmer = PorterStemmer()\n","def stem_words(text):\n","    \"\"\"\n","    Function to stem words, so plural and singular are treated the same\n","    \"\"\"\n","    try:\n","        text = [stemmer.stem(word) for word in text]\n","        text = [word for word in text if len(word) > 1] # make sure we have no 1 letter words\n","    except IndexError: # the word \"oed\" broke this, so needed try except\n","        pass\n","    return text\n","\n","def apply_all(text):\n","    \"\"\"\n","    This function applies all the functions above into one\n","    \"\"\"\n","    return stem_words(remove_stop_words(initial_clean(text)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jaLxajxhSf1s","colab_type":"code","outputId":"7026c784-ee12-4f31-8cc1-bb08193fdcd9","executionInfo":{"status":"ok","timestamp":1587146153415,"user_tz":420,"elapsed":34007,"user":{"displayName":"Subarna Chowdhury Soma","photoUrl":"","userId":"13997249864171991230"}},"colab":{"base_uri":"https://localhost:8080/","height":402}},"source":["\n","news_df = pd.DataFrame( fake_data['text'], columns=['text'])\n","\n","news_df\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Print They should pay all the back all the mon...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Why Did Attorney General Loretta Lynch Plead T...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Red State : \\nFox News Sunday reported this mo...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Email Kayla Mueller was a prisoner and torture...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Email HEALTHCARE REFORM TO MAKE AMERICA GREAT ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>12994</th>\n","      <td>It DOES allow you to put a dog face on top of ...</td>\n","    </tr>\n","    <tr>\n","      <th>12995</th>\n","      <td>Wait till you see what happens to the valuatio...</td>\n","    </tr>\n","    <tr>\n","      <th>12996</th>\n","      <td>I'm waiting for the one that puts a pussy on m...</td>\n","    </tr>\n","    <tr>\n","      <th>12997</th>\n","      <td>$4 Billion even after they are known to be kee...</td>\n","    </tr>\n","    <tr>\n","      <th>12998</th>\n","      <td>of course - how else would they disceminate te...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>12999 rows × 1 columns</p>\n","</div>"],"text/plain":["                                                    text\n","0      Print They should pay all the back all the mon...\n","1      Why Did Attorney General Loretta Lynch Plead T...\n","2      Red State : \\nFox News Sunday reported this mo...\n","3      Email Kayla Mueller was a prisoner and torture...\n","4      Email HEALTHCARE REFORM TO MAKE AMERICA GREAT ...\n","...                                                  ...\n","12994  It DOES allow you to put a dog face on top of ...\n","12995  Wait till you see what happens to the valuatio...\n","12996  I'm waiting for the one that puts a pussy on m...\n","12997  $4 Billion even after they are known to be kee...\n","12998  of course - how else would they disceminate te...\n","\n","[12999 rows x 1 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"41dBSVK3hOpk","colab_type":"code","outputId":"056eed2c-ca72-4479-e41c-596cda679739","executionInfo":{"status":"error","timestamp":1587146153859,"user_tz":420,"elapsed":34448,"user":{"displayName":"Subarna Chowdhury Soma","photoUrl":"","userId":"13997249864171991230"}},"colab":{"base_uri":"https://localhost:8080/","height":690}},"source":["news_df['clean_text'] = news_df['headline'].apply(apply_all)\n","#print ' '.join(word[0] for word in word_list)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'headline'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-44f50f66eeb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnews_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnews_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'headline'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapply_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#print ' '.join(word[0] for word in word_list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'headline'"]}]},{"cell_type":"code","metadata":{"id":"KxR_dLEMTJfI","colab_type":"code","colab":{}},"source":["news_df['headline'] = news_df['text']\n","\n","# Remove punctuation\n","news_df['processed_text'] = news_df['text'].map(lambda x: re.sub('[,\\.!?]', '', str(x)))\n","# Convert the titles to lowercase\n","news_df['processed_text'] = news_df['processed_text'].map(lambda x: x.lower())\n","\n","\n","news_df['text']     = news_df['text'].apply(process_text)\n","news_df['question'] = news_df['text'].apply(question_word)\n","\n","news_df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mBJRLVtXUJET","colab_type":"code","colab":{}},"source":["\n","news_df['num_words']       = news_df['text'].apply(lambda x: len(x.split()))\n","news_df['part_speech']     = news_df['text'].apply(part_of_speech)\n","news_df['num_contract']    = news_df['text'].apply(num_contract)\n","news_df['num_stop_words']  = news_df['text'].apply(cnt_stop_words)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6n8fvbshWPzm","colab_type":"code","colab":{}},"source":["news_df['stop_word_ratio'] = news_df['num_stop_words']/news_df['num_words']\n","news_df['contract_ratio']  = news_df['num_contract']/news_df['num_words']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_YICFF4QUCGh","colab_type":"code","colab":{}},"source":["news_df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"j0WUllqjXJVG","colab_type":"code","colab":{}},"source":["news_df.dtypes"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mHO1BdidXYN-","colab_type":"code","colab":{}},"source":["figure, axes = mp.subplots(figsize=(10,8))\n","sns.heatmap(news_df.corr(), annot=True, vmax=1, linewidths=.5, cmap='Reds')\n","mp.xticks(rotation=45)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N0Nfb11xXrs8","colab_type":"code","colab":{}},"source":["news_df_ = news_df.copy()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"j8qdM4icYBcG","colab_type":"code","colab":{}},"source":["news_df_ "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vd6LrM-MZ6RY","colab_type":"text"},"source":["## Prepare dataframe for training"]},{"cell_type":"code","metadata":{"id":"dvZ17t7kXkDz","colab_type":"code","colab":{}},"source":["news_df.drop(['num_stop_words','num_contract'], axis=1, inplace=True)\n","news_df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PzjdoqsTXw-k","colab_type":"code","colab":{}},"source":["df_train, df_test = train_test_split(news_df, test_size=0.2, random_state=0)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P3zaM_EsaAt0","colab_type":"text"},"source":["## Tf-IDF modeling"]},{"cell_type":"code","metadata":{"id":"10DZmHnQZw5S","colab_type":"code","colab":{}},"source":["tfidf = TfidfVectorizer(min_df=3, max_features=None, strip_accents='unicode',\n","                           analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,5),\n","                           use_idf=1, smooth_idf=1, sublinear_tf=1)\n","\n","X_train_text = tfidf.fit_transform(df_train['text'])\n","X_test_text  = tfidf.transform(df_test['text'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pL6KMW1sai2h","colab_type":"text"},"source":["## Count Vectorizer"]},{"cell_type":"code","metadata":{"id":"b_7x8gf9aiOp","colab_type":"code","colab":{}},"source":["cvec = CountVectorizer()\n","\n","X_train_pos = cvec.fit_transform(df_train['part_speech'])\n","X_test_pos  = cvec.transform(df_test['part_speech'])\n","\n","sc = StandardScaler(with_mean=False)\n","X_train_pos_sc = sc.fit_transform(X_train_pos)\n","X_test_pos_sc  = sc.transform(X_test_pos)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AAvEyPo8jaiB","colab_type":"code","colab":{}},"source":["df_train['clean_text']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"73ELHOmGcqhL","colab_type":"code","colab":{}},"source":["# Load the library with the CountVectorizer method\n","from sklearn.feature_extraction.text import CountVectorizer\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set_style('whitegrid')\n","%matplotlib inline\n","# Helper function\n","def plot_10_most_common_words(count_data, count_vectorizer):\n","    import matplotlib.pyplot as plt\n","    words = count_vectorizer.get_feature_names()\n","    \n","    total_counts = np.zeros(len(words))\n","    for t in count_data:\n","        total_counts+=t.toarray()[0]\n","    \n","    count_dict = (zip(words, total_counts))\n","    count_dict = sorted(count_dict, key=lambda x:x[1], reverse=True)[0:10]\n","    words = [w[0] for w in count_dict]\n","    counts = [w[1] for w in count_dict]\n","    x_pos = np.arange(len(words)) \n","    print(words)\n","    plt.figure(2, figsize=(15, 15/1.6180))\n","    plt.subplot(title='10 most common words')\n","    sns.set_context(\"notebook\", font_scale=1.25, rc={\"lines.linewidth\": 2.5})\n","    sns.barplot(x_pos, counts, palette='husl')\n","    plt.xticks(x_pos, words, rotation=90) \n","    plt.xlabel('words')\n","    plt.ylabel('counts')\n","    plt.show()\n","# Initialise the count vectorizer with the English stop words\n","count_vectorizer = CountVectorizer(stop_words='english')\n","# Fit and transform the processed titles\n","count_data = count_vectorizer.fit_transform(df_train['text'])\n","# Visualise the 10 most common words\n","plot_10_most_common_words(count_data, count_vectorizer)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vNwcHrQclch3","colab_type":"text"},"source":["## LDA modeling"]},{"cell_type":"code","metadata":{"id":"vsMgp3o5lZHG","colab_type":"code","colab":{}},"source":["import warnings\n","warnings.simplefilter(\"ignore\", DeprecationWarning)\n","# Load the LDA model from sk-learn\n","from sklearn.decomposition import LatentDirichletAllocation as LDA\n"," \n","# Helper function\n","def print_topics(model, count_vectorizer, n_top_words):\n","    words = count_vectorizer.get_feature_names()\n","    for topic_idx, topic in enumerate(model.components_):\n","        print(\"\\nTopic #%d:\" % topic_idx)\n","        print(\" \".join([words[i]\n","                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n","        \n","# Tweak the two parameters below\n","number_topics = 5\n","number_words = 10\n","# Create and fit the LDA model\n","lda = LDA(n_components=number_topics, n_jobs=-1)\n","lda.fit(count_data)\n","# Print the topics found by the LDA model\n","print(\"Topics found via LDA:\")\n","print_topics(lda, count_vectorizer, number_words)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fl8slD-8nke9","colab_type":"code","colab":{}},"source":["print_topics(lda, number_topics, number_words)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bo28V-gwbkDU","colab_type":"text"},"source":["## Reference"]},{"cell_type":"markdown","metadata":{"id":"ZuznRa-ubmDh","colab_type":"text"},"source":["* https://www.nltk.org/book/ch05.html\n","* https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0"]}]}