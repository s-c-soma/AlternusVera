{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (Capstone)",
      "language": "python",
      "name": "capstonepython3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Factor-NewsCoverage-ScoreComputing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s-c-soma/AlternusVera/blob/master/TheMeanSquares_AlternusVera/News%20Coverage_Subarna/Factor_NewsCoverage_ScoreComputing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mm0E3JG_8rbk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "0849629a-873e-4831-923c-6fe26ea2f556"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jp43ddES8ZO8"
      },
      "source": [
        "# Part Two - Analysing related article sentiment and bias\n",
        "This workbook considers the second part of the project - taking a group of related articles and assessing their sentiment and scope for bias.\n",
        "In an ideal world, where we each want to have a fair and balanced view on every topic, we would hope to read articles covering a range of perspectives on the same story.\n",
        "Having developed the means to find related articles in part one of this project, this part applies several sentiment analysis techniques to look at the distribution of their sentiment. It ultimately arrives at a score to convey how balanced the coverage of a story is."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4-gCwGt8ZO9"
      },
      "source": [
        "## Preparation\n",
        "### Imports\n",
        "First some of the required packages must be imported."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7yETHXThH39"
      },
      "source": [
        "### Import Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2fm9Gtz8ZO-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "b717d3c9-1e9d-4587-e02f-7b6540dbceaf"
      },
      "source": [
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import operator\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk as nl\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "import statistics\n",
        "import random\n",
        "import warnings\n",
        "import re\n",
        "from matplotlib import pyplot\n",
        "from pandas import Series, datetime\n",
        "from pandas.plotting import scatter_matrix, autocorrelation_plot\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV, TimeSeriesSplit\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_7T4u4K8ZPB"
      },
      "source": [
        "### Parameter configuration\n",
        "The parameters used to control the NLP-related calculations, and to specify the domain for any grid search are captured in the runParams dict. This includes specification of the location of the key input files.\n",
        "The runParams dict is converted into an sklearn ParameterGrid, even if there is no grid search requirement (in which case it's processed as a single scenario grid search)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpZCy0YD8ZPC"
      },
      "source": [
        "#'google','vader','stanford'\n",
        "runParams={'sentiment_library':   ['vader'],\n",
        "           'input_file':          ['/content/drive/My Drive/Colab Notebooks/articles1.csv'],\n",
        "           'output_file':         ['/content/drive/My Drive/Colab Notebooks/fakenews_by_news-coverage.csv'],\n",
        "           'article_id_list':     [[120639,80103,25225,21502,57362,120636]],\n",
        "           'sentiment_sentences': [5],\n",
        "           'article_stats':       [False]}\n",
        "\n",
        "# Use parameter grid even if there is only set of parameters\n",
        "parameterGrid=ParameterGrid(runParams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGEaKJsQtNaz"
      },
      "source": [
        "#financial_stock_data =  pd.read_csv('/content/drive/My Drive/Colab Notebooks/articles1.csv', low_memory =False)\n",
        "#financial_stock_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4xIBV7b8ZPE"
      },
      "source": [
        "### File loader for news corpus\n",
        "\n",
        "This is the same function as used in Part One."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NndfG1gV8ZPF"
      },
      "source": [
        "def getInputDataAndDisplayStats(filename,processDate,printSummary=False):\n",
        "\n",
        "\tdf=pd.read_csv(filename)\n",
        "\n",
        "\tdf=df.drop_duplicates('content')\n",
        "\tdf=df[~df['content'].isnull()]\n",
        "\n",
        "\t\n",
        "\tdf=df[df['content'].str.len()>=200]\n",
        "\n",
        "\t# Find and remove summary NYT \"briefing\" articles to avoid confusing the clustering\n",
        "\ttargetString=\"(Want to get this briefing by email?\"\n",
        "\tdf['NYT summary']=df['content'].map(lambda d: d[:len(targetString)]==targetString)\n",
        "\tdf=df[df['NYT summary']==False]\n",
        "\n",
        "\t# The following removes a warning that appears in many of the Atlantic articles.\n",
        "\t# Since it is commonly at the beginning, it brings a lot of noise to the search for similar articles\n",
        "\t# And subsequently to the assessment of sentiment\n",
        "\ttargetString=\"For us to continue writing great stories, we need to display ads.             Please select the extension that is blocking ads.     Please follow the steps below\"\n",
        "\tdf['content']=df['content'].str.replace(targetString,'')\n",
        "\n",
        "\t# This is also for some Atlantic articles for the same reasons as above\n",
        "\ttargetString=\"This article is part of a feature we also send out via email as The Atlantic Daily, a newsletter with stories, ideas, and images from The Atlantic, written specially for subscribers. To sign up, please enter your email address in the field provided here.\"\n",
        "\tdf=df[df['content'].str.contains(targetString)==False]\n",
        "\n",
        "\t# This is also for some Atlantic articles for the same reasons as above\n",
        "\ttargetString=\"This article is part of a feature we also send out via email as Politics  Policy Daily, a daily roundup of events and ideas in American politics written specially for newsletter subscribers. To sign up, please enter your email address in the field provided here.\"\n",
        "\tdf=df[df['content'].str.contains(targetString)==False]\n",
        "\n",
        "\t# More Atlantic-specific removals (for daily summaries with multiple stories contained)\n",
        "\tdf=df[df['content'].str.contains(\"To sign up, please enter your email address in the field\")==False]\n",
        "\n",
        "\t# Remove daily CNN summary\n",
        "\ttargetString=\"CNN Student News\"\n",
        "\tdf=df[df['content'].str.contains(targetString)==False]\n",
        "\n",
        "\tif printSummary:\n",
        "\t\tprint(\"\\nArticle counts by publisher:\")\n",
        "\t\tprint(df['publication'].value_counts())\n",
        "\n",
        "\t\tprint(\"\\nArticle counts by date:\")\n",
        "\t\tprint(df['date'].value_counts())\n",
        "\t\t\n",
        "\t# Restrict to articles on the provided input date.\n",
        "\t# This date is considered mandatory for topic clustering but is not required for sentiment\n",
        "\t# since sentiment only processes a specified list of articles.\n",
        "\t# For topic clustering it is essential to have the date as it is\n",
        "\t# enormously significant in article matching.\n",
        "\tif processDate!=None:\n",
        "\t\tdf=df[df['date']==processDate]\n",
        "\tdf.reset_index(inplace=True, drop=True)\n",
        "\n",
        "\t# Remove non-ASCII characters\n",
        "\tdf['processed_content']=df['content'].map(lambda x: removeNonASCIICharacters(x))\n",
        "\tdf['score'] = 0.0\n",
        "\n",
        "\tprint(\"\\nFinal dataset:\\n\\nDate:\",processDate,\"\\n\")\n",
        "\tprint(df['publication'].value_counts())\n",
        "\n",
        "\treturn df\n",
        "\n",
        "##########################################################################################\n",
        "\n",
        "def removeNonASCIICharacters(textString): \n",
        "    return \"\".join(i for i in textString if ord(i)<128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9fc8s7a8ZPH"
      },
      "source": [
        "### Load the articles from the corpus\n",
        "In addition the function will return the number of articles per publication (for the requested run date). Here we see there is a relatively good mix of political viewpoints covered. More discussion of this is provided in the project report."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NklfN7BF8ZPI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "30126fe0-d43a-46fc-ade8-5267bc3b8609"
      },
      "source": [
        "articleDataFrame=getInputDataAndDisplayStats(runParams['input_file'][0],None,False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Final dataset:\n",
            "\n",
            "Date: None \n",
            "\n",
            "Breitbart           23585\n",
            "CNN                 11249\n",
            "New York Times       7620\n",
            "Business Insider     6504\n",
            "Atlantic              157\n",
            "Name: publication, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGjOb_ykkbct",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "0884c82c-512c-4aa4-88a3-c2ce13fc3a59"
      },
      "source": [
        "articleDataFrame.date.unique"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Series.unique of 0        2016-12-31\n",
              "1        2017-06-19\n",
              "2        2017-01-06\n",
              "3        2017-04-10\n",
              "4        2017-01-02\n",
              "            ...    \n",
              "49110    2017-01-11\n",
              "49111    2017-01-11\n",
              "49112    2017-01-11\n",
              "49113    2017-01-11\n",
              "49114    2017-01-11\n",
              "Name: date, Length: 49115, dtype: object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0eSNzJekhRe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09e68e46-e8f2-4a60-e25a-bc83833e9990"
      },
      "source": [
        "articleDataFrame.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49115, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOBqsNtOmAm_"
      },
      "source": [
        "col_id_list = articleDataFrame['id'].tolist()\n",
        "#col_id_list \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nTFpbXJndRY"
      },
      "source": [
        "### Take All Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZCu0nSw-v4O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "79b1b1f5-6a66-4983-844f-0dd73cdcea7a"
      },
      "source": [
        " articleDataFrame['id'].count()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49115"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycCi_1jkxKiP"
      },
      "source": [
        "Comment this line if not want to take all the IDs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4dXTFM7mwrK"
      },
      "source": [
        "##runParams['article_id_list'][0] = col_id_list "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwaJ31vH8ZPc"
      },
      "source": [
        "## News Coverage computation methods\n",
        "These are to determine a score for how well a set of documents manages to cover a variety of perspectives..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blmmXx8P8ZPK"
      },
      "source": [
        "### NC-Score: Sentiment analysis\n",
        "Three NLP libraries are supported for this part of the project: Vader, Google, and Stanford Core NLP. Classes will be defined to enable each of them.\n",
        "### Parent Sentiment Analysis Class\n",
        "The main sentiment analyser class provides a consistent wrapper and interface around classes specific to the various NLP libraries. Its constructor creates and embeds an instance of the appropriate class. It provides additional standard interfaces to trigger the analysis on an article, and to return the overall score for that article.\n",
        "Additionally it manages the scaling of results across classes in order to facilitate consistency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8e6f89MaKKl"
      },
      "source": [
        "class SentimentAnalyser():\n",
        "\n",
        "\tscaleMin=-1.\n",
        "\tscaleMax=1.\n",
        "\n",
        "    # Initializer / Instance attributes\n",
        "\tdef __init__(self, library):\n",
        "\t\tif library=='vader':\n",
        "\t\t\tself.analyser=NLTKVaderSentimentAnalyser()\n",
        "\t\telse:\n",
        "\t\t\tprint(\"ERROR - NO RECOGNISED LIBRARY\")\n",
        "\n",
        "\tdef getOverallArticleScore(self,articleResults):\n",
        "\n",
        "\t\t# Google returns a document score, but it is an int, which is useful when comparing documents\n",
        "\t\t# Hence computing the average of the sentences here instead\n",
        "\t\t# Google's document score is here: articleResults.document_sentiment.score\n",
        "\t\tnumSentences=0.\n",
        "\t\ttotalSentScore=0.\n",
        "\t\tfor sentence in articleResults:\n",
        "\t\t\tnumSentences+=1\n",
        "\t\t\ttotalSentScore+=self.analyser.getSentenceScoreFromResults(sentence)\n",
        "\n",
        "\t\tvalue=(totalSentScore/numSentences-self.analyser.scaleMin)/(self.analyser.scaleMax-self.analyser.scaleMin)\n",
        "\t\treturn self.scaleMin+value*(self.scaleMax-self.scaleMin)\n",
        "\n",
        "\tdef generateResults(self,textToAnalyse):\n",
        "\t\treturn self.analyser.generateResults(textToAnalyse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMJdtZPFaX08"
      },
      "source": [
        "### Vader library class\n",
        "This class does the same thing for using the VADER sentiment analyser packaged with NLTK."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyOY_fgpadXj"
      },
      "source": [
        "class NLTKVaderSentimentAnalyser():\n",
        "# Per NLTK Vader user guide: https://pypi.org/project/vaderSentiment/\n",
        "# Typical threshold values (used in the literature cited on this page) are: \n",
        "#. **positive sentiment**: ``compound`` score >= 0.05 \n",
        "#. **neutral sentiment**: (``compound`` score > -0.05) and (``compound`` score < 0.05) \n",
        "#. **negative sentiment**: ``compound`` score <= -0.05 \n",
        "\n",
        "\tscaleMin=-1.\n",
        "\tscaleMax=1.\n",
        "\n",
        "\tdef __init__(self):\n",
        "\t\tself.nltkVaderAnalyser=SentimentIntensityAnalyzer()\n",
        "\t\treturn\n",
        "\n",
        "\tdef generateResults(self,textToAnalyse):\n",
        "\t\tss=[]\n",
        "\t\tfor sentence in nl.sent_tokenize(textToAnalyse):\n",
        "\t\t\tss.append(self.nltkVaderAnalyser.polarity_scores(sentence))\n",
        "\t\treturn ss\n",
        "\n",
        "\tdef getSentenceScoreFromResults(self,sentenceResults):\n",
        "\t\treturn sentenceResults['compound']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbJAGMBmagOE"
      },
      "source": [
        "### Computing Balance Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW5C3-_t8ZPc"
      },
      "source": [
        "def computePopulationBalanceScore(articleScoreDict,sentimentClass):\n",
        "\t# Extract values from dict, then normalise to be within -1 to +1\n",
        "\t# Then compute population standard deviation as the balance score\n",
        "\tpopulation=[-1.+(x-sentimentClass.scaleMin)/(sentimentClass.scaleMax-sentimentClass.scaleMin)*(1.-(-1.)) for x in articleScoreDict.values()]\n",
        "\treturn statistics.pstdev(population)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay6_9UQHaoN9"
      },
      "source": [
        "### Overall- Avg Score Computation for Story"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXu0UoVR2moK"
      },
      "source": [
        "def computePopulationBalanceScoreHistoMean(articleScoreDict,sentimentClass):\n",
        "\t# Extract values from dict, then normalise to be within -1 to +1\n",
        "\t# Then compute population standard deviation as part of the balance score\n",
        "\tnumBuckets=len(articleScoreDict)\n",
        "\tarticleValues=pd.Series(articleScoreDict)\n",
        "\t\n",
        "\t# Based on 10,000 random article samples, Google's sentiment score for these articles lies within +/- 0.86\n",
        "\t# So, scale all scores by dividing by that value to rescale to +/- 1.00 before computing balance score\n",
        "\t# Ideally this should factored in at the individual NLP library class level \n",
        "\tarticleValues=articleValues/0.86\n",
        "\n",
        "\tpopulatedBuckets=0\n",
        "\tfor i in range(numBuckets):\n",
        "\t\tbucketFrom=sentimentClass.scaleMin+i*(sentimentClass.scaleMax-sentimentClass.scaleMin)/numBuckets\n",
        "\t\tbucketTo=bucketFrom+(sentimentClass.scaleMax-sentimentClass.scaleMin)/numBuckets\n",
        "\t\t# The following is to ensure the top of the highest bucket is counted somewhere\n",
        "\t\t# and doesn't fall out due to treatment of inequalities in ranges\n",
        "\t\tif bucketTo==sentimentClass.scaleMax:\n",
        "\t\t\tbucketTo+=0.001\n",
        "\t\tnumSamples=((bucketFrom<=articleValues) & (articleValues<bucketTo)).sum()\n",
        "\t\tif numSamples>0:\n",
        "\t\t\tpopulatedBuckets+=1\n",
        "\n",
        "\t# Score computed as proportion of buckets which are populated (more buckets implies a more balanced view)\n",
        "\t# This has a value between 0 and 1.\n",
        "\t# This is in turn multiplied by the distance between the mean and 1.\n",
        "\t# So, if mean is in center (i.e. at 0) then things are balanced, so score is not decreased\n",
        "\t# Otherwise, score is decreased proportionately\n",
        "\treturn (populatedBuckets/numBuckets * (1.-abs(articleValues.mean())))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-lgXGZQtP7F"
      },
      "source": [
        "### NC-Score: News Source Credibility "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Duto2ThS8ZPf"
      },
      "source": [
        "## Story map loading\n",
        "The story map file is an optional way to provide the algorithm with:\n",
        "- A list of stories\n",
        "- Each story has a name (for reference/convenience)\n",
        "- Each story contains a list of articles that pertain to that story\n",
        "\n",
        "The objective is ultimately to process each story, and within each story to measure the sentiment of each article, then (still within the story) to compute the score for the balance of the coverage (of that story).\n",
        "\n",
        "This section of code is taken from the other workbook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23gl8ZIC8ZPf"
      },
      "source": [
        "def setupStoryMapAndReportList(args=None,reportArticleList=None,storyMapFileName=None):\n",
        "\t# Story Map is used in fitting if grid search is applied (As ground truth)\n",
        "\t# It is also used in graph if no threshold provided (to determine colours, not to determine location)\n",
        "\t# Report Article List is used at the end to create a report with, for each\n",
        "\t# article in the list, the set of articles within tolerance, and the key words for each\n",
        "\tif args==None:\n",
        "\t\tarticleList=reportArticleList\n",
        "\t\tfileName=storyMapFileName\n",
        "\telse:\n",
        "\t\tarticleList=args['article_id_list']\n",
        "\t\tfileName=args['story_map_validation']\n",
        "\n",
        "\treportArticleList=articleList\n",
        "\tif fileName!=None:\n",
        "\t\tstoryMap=readStoryMapFromFile(fileName)\n",
        "\t\tif reportArticleList==None:\n",
        "\t\t\treportArticleList=[]\n",
        "\t\t\tfor story, articleList in storyMap.items():\n",
        "\t\t\t\treportArticleList.append(articleList[0])\n",
        "\telse:\n",
        "\t\tstoryMap=None\n",
        "\treturn storyMap,reportArticleList\n",
        "\n",
        "def readStoryMapFromFile(filename):\n",
        "\treturn readDictFromCsvFile(filename,'StoryMap')\n",
        "\n",
        "##########################################################################################\n",
        "\n",
        "def readGridParameterRangeFromFile(filename):\n",
        "\treturn readDictFromCsvFile(filename,'GridParameters')\n",
        "\n",
        "##########################################################################################\n",
        "\n",
        "def readDictFromCsvFile(filename,schema):\n",
        "\tgridParamDict={}\n",
        "\twith open(filename, 'r') as f:\n",
        "\t\tfor row in f:\n",
        "\t\t\trow=row[:-1] # Exclude the carriage return\n",
        "\t\t\trow=row.split(\",\")\n",
        "\t\t\tkey=row[0]\n",
        "\t\t\tvals=row[1:]\n",
        "\t\t\t\n",
        "\t\t\tif schema=='GridParameters':\n",
        "\t\t\t\tif key in ['story_threshold','tfidf_maxdf']:\n",
        "\t\t\t\t\tfinalVals=list(float(n) for n in vals)\n",
        "\t\t\t\telif key in ['ngram_max','tfidf_mindf','max_length']:\n",
        "\t\t\t\t\tfinalVals=list(int(n) for n in vals)\n",
        "\t\t\t\telif key in ['lemma_conversion','tfidf_binary']:\n",
        "\t\t\t\t\tfinalVals=list(str2bool(n) for n in vals)\n",
        "\t\t\t\telif key in ['parts_of_speech']:\n",
        "\t\t\t\t\tlistlist=[]\n",
        "\t\t\t\t\tfor v in vals:\n",
        "\t\t\t\t\t\tlistlist.append(v.split(\"+\"))\n",
        "\t\t\t\t\tfinalVals=listlist\n",
        "\t\t\t\telif key in ['tfidf_norm','nlp_library']:\n",
        "\t\t\t\t\tfinalVals=vals\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tprint(key)\n",
        "\t\t\t\t\tprint(\"KEY ERROR\")\n",
        "\t\t\t\t\treturn\n",
        "\t\t\telif schema=='StoryMap':\n",
        "\t\t\t\tfinalVals=list(int(n) for n in vals)\n",
        "\t\t\telse:\n",
        "\t\t\t\tprint(schema)\n",
        "\t\t\t\tprint(\"SCHEMA ERROR\")\n",
        "\t\t\t\treturn\n",
        "\t\t\t\n",
        "\t\t\tgridParamDict[key]=finalVals\n",
        "\treturn gridParamDict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0VLEb5X8ZPh"
      },
      "source": [
        "### Load the story map from file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XscYUHIfxduh"
      },
      "source": [
        "storyMap,reportArticleList=setupStoryMapAndReportList(storyMapFileName='/content/drive/My Drive/Colab Notebooks/storyMapForValidation1.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STsKeSUD8ZPi"
      },
      "source": [
        "storyMap,reportArticleList=setupStoryMapAndReportList(None,None,None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5xwgPMF8ZPj"
      },
      "source": [
        "Inspecting the story map we see that it forms a dict containing a key corresponding to the name of the story and a value containing a list of the article IDs germane to that story."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjgqDiPH8ZPk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22fe3dc5-108f-4dc8-a57d-ff14fec771f4"
      },
      "source": [
        "if storyMap is None:\n",
        "  print('')\n",
        "else:\n",
        "  for story, articleList in storyMap.items():\n",
        "    print(story,\":\",articleList)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uC_2iWGg8ZPm"
      },
      "source": [
        "### Augment story map with user requested specific article list\n",
        "A requested article list is explicitly part of the input parameters and may vary through each iteration of the main loop. This data may not be consistent with any provided story map file. So the following function will be required in order to reconcile any differences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NaWd52j8ZPm"
      },
      "source": [
        "def collapseRequestedArticleListIntoStoryList(requestedArticleList,storyMap):\n",
        "\t# Check that the explicitly requested articles are all contained in the storyList\n",
        "\t# If they aren't, add a new story to contain them\n",
        "\n",
        "\t# If the storyMap was empty, it will be None,\n",
        "\t# so initialise as a dictionary ready for adding new values\n",
        "\tif storyMap==None:\n",
        "\t\tnewStoryMap={}\n",
        "\telse:\n",
        "\t\tnewStoryMap=storyMap.copy()\n",
        "\n",
        "\tfound=False\n",
        "\tfor story,articleListFromMap in newStoryMap.items():\n",
        "\t\tif len(articleListFromMap)==len(requestedArticleList):\n",
        "\t\t\ty=sum([x in articleListFromMap for x in requestedArticleList])\n",
        "\t\t\tif y==len(articleListFromMap):\n",
        "\t\t\t\tfound=True\n",
        "                \n",
        "\t# If there is no complete story exactly matching then add a new story to the list\n",
        "\t# With the first article ID as the key (arbitrarily)\n",
        "\tif not found:\n",
        "\t\tnewStoryMap[requestedArticleList[0]]=requestedArticleList\n",
        "\tprint('newStoryMap',newStoryMap)\n",
        "\treturn newStoryMap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWh1uhoa8ZPo"
      },
      "source": [
        "## Main Process Run\n",
        "Note that the earlier steps need to have been run before this step in order to populate the following:\n",
        "- articleDataFrame\n",
        "- parameterGrid\n",
        "\n",
        "\n",
        "\n",
        "Vader will operate without any additional constraints, providing the Python environment has all the correct packages, per my project requirements file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xed0iev1bPbU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "edb80405-4bd5-40c1-a1eb-4d764b37f889"
      },
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvdNPztACExr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "d412d173-1586-412c-dfd5-34ea5859cc4f"
      },
      "source": [
        "for i,currentParams in enumerate(parameterGrid):\n",
        "  if len(parameterGrid)>1:\n",
        "    print(\"Combination:\",i+1,\"of\",len(parameterGrid))\n",
        "    print(currentParams)\n",
        "\n",
        "  iterationStoryMap=collapseRequestedArticleListIntoStoryList(currentParams['article_id_list'],storyMap)\n",
        "  sentimentAnalyser=SentimentAnalyser(currentParams['sentiment_library'])\n",
        "\n",
        "  for story,articleList in iterationStoryMap.items():\n",
        "    articleSentScores={}\n",
        "    print(\"ANALYSING STORY:\",story,\"using\",currentParams['sentiment_library'])\n",
        "    print(\"Number of articles in story:\",len(articleList))\n",
        "\n",
        "    for article in articleList:\n",
        "      articleContent=articleDataFrame[articleDataFrame['id']==article].iloc[0]['content']\n",
        "      if currentParams['sentiment_sentences']!=None:\n",
        "\t      articleSentences=nl.sent_tokenize(articleContent)\n",
        "\t      textToAnalyse=' '.join(articleSentences[:currentParams['sentiment_sentences']])\t\n",
        "      else:\n",
        "\t      textToAnalyse=articleContent\n",
        "\n",
        "      results=sentimentAnalyser.generateResults(textToAnalyse)\n",
        "      articleSentScores[article]=sentimentAnalyser.getOverallArticleScore(results)\n",
        "    \n",
        "    # Sort and display results\n",
        "    sortedArticleSentScores=sorted(articleSentScores.items(), key=operator.itemgetter(1))\n",
        "    print(\"\\nArticle sentiments, most positive first:\")\n",
        "    for article in reversed(sortedArticleSentScores):\n",
        "\t      print(article[0],\":\", round(article[1],3),articleDataFrame[articleDataFrame['id']==article[0]].iloc[0]['publication'])\n",
        "\t      articleDataFrame.at[articleDataFrame[articleDataFrame['id']==article[0]].index[0],'score'] = round(article[1],3)\n",
        "    \n",
        "\n",
        "    print(\"\\nNEWS COVERAGE SCORE:\",round(computePopulationBalanceScoreHistoMean(articleSentScores,SentimentAnalyser),3),\"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "newStoryMap {120639: [120639, 80103, 25225, 21502, 57362, 120636]}\n",
            "ANALYSING STORY: 120639 using vader\n",
            "Number of articles in story: 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-15751a5f37b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0marticle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marticleList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m       \u001b[0marticleContent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marticleDataFrame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marticleDataFrame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mcurrentParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment_sentences'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m               \u001b[0marticleSentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticleContent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2137\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2138\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2140\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2061\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2062\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2063\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pe8t8gk8ZPq"
      },
      "source": [
        "## Output inspection\n",
        "To inspect the raw content of one of the articles, substitute the desired ID in the following command and run it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ZF2Fl1gX8ZPr"
      },
      "source": [
        "articleDataFrame[articleDataFrame['id']==80103]#['content'].values[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q2Vd36k474q"
      },
      "source": [
        "## Fakeness Label from News Coverage Score\n",
        "\n",
        "* positive sentiment: ``compound`` score >= 0.05 \n",
        "* neutral sentiment: (``compound`` score > -0.05) and (``compound`` score < 0.05) \n",
        "* negative sentiment: ``compound`` score <= -0.05 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJz0W-auq1p9"
      },
      "source": [
        "###param try1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYY7WNQT5GSh"
      },
      "source": [
        "articleDataFrame.loc[articleDataFrame.score >= 0.05, 'label_NewsCoverage'] = 1 # true news\n",
        "articleDataFrame.loc[((articleDataFrame.score > -0.05) & (articleDataFrame.score < 0.05 )), 'label_NewsCoverage'] = 2 # avg\n",
        "articleDataFrame.loc[articleDataFrame.score <= -0.05, 'label_NewsCoverage'] = 0 # fake news\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-iFO6w4q_SK"
      },
      "source": [
        "###param try2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYjycSz_orUq"
      },
      "source": [
        "articleDataFrame.loc[articleDataFrame.score >= 0.00, 'label_NewsCoverage'] = 1 # true news\n",
        "#articleDataFrame.loc[((articleDataFrame.score > -0.05) & (articleDataFrame.score < 0.05 )), 'label_NewsCoverage'] = 2 # avg\n",
        "articleDataFrame.loc[articleDataFrame.score < 0.00, 'label_NewsCoverage'] = 0 # fake news"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-txiu3ybUUUT"
      },
      "source": [
        "print(\"Size of the Labels column\")\n",
        "print(articleDataFrame.groupby('label_NewsCoverage').size())\n",
        "articleDataFrame['label_NewsCoverage'].value_counts().plot(kind=\"bar\")\n",
        "plt.ylabel('label_NewsCoverage')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h8QSobw8sCv"
      },
      "source": [
        "articleDataFrame[articleDataFrame.id.isin([120639, 80103, 25225, 21502, 57362, 120636])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfXRpoV_ZRgT"
      },
      "source": [
        "## Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyv0zC4ubDx0"
      },
      "source": [
        "### Test and Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtU4l-CVd-Y9"
      },
      "source": [
        "articleDataFrame[\"label_NewsCoverage\"] = articleDataFrame[\"label_NewsCoverage\"].astype('int')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvXjIHutbOIK"
      },
      "source": [
        "articleDataFrame.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8zMZ2pqbJf3"
      },
      "source": [
        "# Separate the dataframe for input(X) and output variables(y)\n",
        "#['Unnamed: 0', 'id', 'title', 'publication', 'author', 'date', 'year','month', 'url', 'content', 'NYT summary', 'processed_content','score', 'label_NewsCoverage']\n",
        "X = articleDataFrame['processed_content']\n",
        "Y = articleDataFrame['label_NewsCoverage']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_tQ2ES7nYin"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3)\n",
        "X_train = np.array(X_train);\n",
        "X_test = np.array(X_test);\n",
        "Y_train = np.array(Y_train);\n",
        "Y_test = np.array(Y_test);\n",
        "cleanHeadlines_train = [] #To append processed headlines\n",
        "cleanHeadlines_test = [] #To append processed headlines\n",
        "number_reviews_train = len(X_train) #Calculating the number of reviews\n",
        "number_reviews_test = len(X_test) #Calculating the number of reviews"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un1Fer9pnp1A"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "def get_words( headlines ):               \n",
        "    headlines_onlyletters = re.sub(\"[^a-zA-Z]\", \" \",headlines) #Remove everything other than letters     \n",
        "    words = headlines_onlyletters.lower().split() #Convert to lower case, split into individual words    \n",
        "    stops = set(stopwords.words(\"english\"))  #Convert the stopwords to a set for improvised performance                 \n",
        "    meaningful_words = [w for w in words if not w in stops]   #Removing stopwords\n",
        "    return( \" \".join( meaningful_words )) #Joining the words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BNZf1K0ntcz"
      },
      "source": [
        "for i in range(0,number_reviews_train):\n",
        "    cleanHeadline = get_words(X_train[i]) #Processing the data and getting words with no special characters, numbers or html tags\n",
        "    cleanHeadlines_train.append( cleanHeadline )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VG1zFAGoDeb"
      },
      "source": [
        "for i in range(0,number_reviews_test):\n",
        "    cleanHeadline = get_words(X_test[i]) #Processing the data and getting words with no special characters, numbers or html tags\n",
        "    cleanHeadlines_test.append( cleanHeadline )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgV2VXTOoGah"
      },
      "source": [
        "#vectorize = CountVectorizer(stop_words='english')\n",
        "vectorize = CountVectorizer(analyzer = \"word\",max_features = 1700)    #(stop_words='english')\n",
        "bagOfWords_train = vectorize.fit_transform(cleanHeadlines_train)\n",
        "X_train = bagOfWords_train.toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKaEM_KEoLWx"
      },
      "source": [
        "bagOfWords_test = vectorize.transform(cleanHeadlines_test)\n",
        "X_test = bagOfWords_test.toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTfm8nCvpnyR"
      },
      "source": [
        "### Auto ML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS9Sk93Kon8V"
      },
      "source": [
        "num_folds = 10\n",
        "seed = 7\n",
        "scoring = 'accuracy'\n",
        "\n",
        "models = []\n",
        "models.append(('LR' , LogisticRegression()))\n",
        "models.append(('LDA' , LinearDiscriminantAnalysis()))\n",
        "#models.append(('KNN' , KNeighborsClassifier()))\n",
        "#models.append(('CART' , DecisionTreeClassifier()))\n",
        "#models.append(('NB' , GaussianNB()))\n",
        "#models.append(('SVM' , SVC()))\n",
        "models.append(('MNB', MultinomialNB()))\n",
        "models.append(('RF' , RandomForestClassifier(n_estimators=50)))\n",
        "#models.append(('XGBoost', XGBClassifier()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-b3R6GGpCqk"
      },
      "source": [
        "results = []\n",
        "names = []\n",
        "\n",
        "'''\n",
        "for name, model in models:\n",
        "    kfold = KFold(n_splits=num_folds, random_state=42)\n",
        "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "    print(msg) '''\n",
        "\n",
        "for name, model in models:\n",
        "    clf = model\n",
        "    clf.fit(X_train, Y_train)\n",
        "    Y_pred = clf.predict(X_test)\n",
        "    accu_score = accuracy_score(Y_test, Y_pred)\n",
        "    print(name + \": \" + str(accu_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpI_qjvF3bPC"
      },
      "source": [
        "## Save to CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6X5HtK22-Fq"
      },
      "source": [
        "articleDataFrame.to_csv (runParams['output_file'][0], index = False, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}