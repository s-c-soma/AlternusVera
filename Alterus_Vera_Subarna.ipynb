{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Alterus_Vera_Subarna.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s-c-soma/AlternusVera/blob/master/Alterus_Vera_Subarna.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wQQSqp-V7cE",
        "colab_type": "text"
      },
      "source": [
        "This NoteBook Is Part of the Ongoing Alterus Vera Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JG8gbRPAZQgj",
        "colab_type": "text"
      },
      "source": [
        "<h1>Alternus Vera - Final Version - Hyunwook Shin</h1>\n",
        "\n",
        "November 25, 2018\n",
        "012507417"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1UkVSmlOB-j",
        "colab_type": "text"
      },
      "source": [
        "Link to the main group notebook from previous week(s):\n",
        "\n",
        "https://colab.research.google.com/drive/1bOoY6V0ytxSigKuZ6lJntNWJJcTM_6wU#scrollTo=ebnN4ikZzQtu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWBbJqDFhN5p",
        "colab_type": "text"
      },
      "source": [
        "## Subarna Chowdhury Soma"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJKaCuStfGCW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5336bda9-fe72-4470-8e4f-3e368abd2c61"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-8OIZALZUHv",
        "colab_type": "text"
      },
      "source": [
        "## 1 Introduction\n",
        "\n",
        "I will be focusing on the two main features, namely **event coverage** (initially recency) and **political spectrum**,  which are factors in determining if the news is genuine or fake news, as shown below:\n",
        "\n",
        "| Factor | Explanation|\n",
        "| -- | -- |\n",
        "| Coverage of the latent event from outside sources  | Level of coverage regarding the latent event or topic  | \n",
        "| Political Bias | number from 0 to 10 where 0 is central/neutral and 10 is partisan (left/right) |\n",
        "\n",
        "The event coverage is the factor I put my most personal effort in, covering all areas of distillation (preprocessing, LDA, sentiment analysis) and generating resultant csv files for generating polynomial equation. Politicial bias factor was also researched as part of bonus/extra study.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt-lad4IyrUd",
        "colab_type": "text"
      },
      "source": [
        "High level overview with diagrams are available under the following lin:\n",
        "\n",
        "https://drive.google.com/file/d/1Pys9cj0_NlZdIH3Jwz6lA4FPAPujx54B/view?usp=sharing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Wgdn_o7Ac7M",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 Contribution - Team\n",
        "\n",
        "- Sy Le (006088940) : data import and wrangling, tokenization, remove stopwords, remove stemmings\n",
        "- Mojdeh Keykhanzadeh(008129589) : remove punctuation , apply ngrams,researched about IBM Faireness\n",
        "- **Hyunwook Shin (012507417) : Coverage Score and Political Bias/Spectrum Analysis, Data enrichment:\n",
        "  all news dataset (50K+ articles), political messages dataset (LDA, TF-IDF, MultinomialNB)**\n",
        "- Lin Cheng (012484459) : Use TF-IDF Vectorizer + SVD to produce a matrix, and apply Logistic Regression on it\n",
        "- Yu Xu (012502048): Explored ways to gather topics from the dataset. Explored tf-idf ranking. Explored pipeline + GridSearch for the best n_component of LDA for logistic regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOKUHCJAFRDb",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 Contribution - Notebook\n",
        "\n",
        "The following notebook is prepared by Hyunwook Shin. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jam6zuoEmXz",
        "colab_type": "text"
      },
      "source": [
        "### 1.3 Motivations\n",
        "\n",
        "The main motivation behind **event coverage** is the hypothesis that there is a positive corelation between outside coverage of the latents event depicted in the article and the creditbility and ultimately truthfulness of the article as a whole.  In other words, the more news sources (outside the article) talk about the same event, the more credible the article is as a whole. Some fake news are designed to confuse audiences and make them lose trust in reliable news (Shu et al, 2017). \n",
        "\n",
        "We as readers do this from day to day when we read sensational or eye-catching articles. When we read an article about a topic we think is \"too good to be true\", we cross-check with other news websites under Google News or Twitter to read up on the event or topic. This is backed by the idea that there are fake users and bot account purposely desigend to spread false stories (Shu et al., 2017).  **Through tips and advice on slack, just because there are ample number of coverage on some topic, it does not necessarily mean that the particular article in question is a reliable (non-fake news).** (Arsanjani, 2018). This factor should be used in conjunction with other factors such as \"bias\", \"sensationalism\", and \"social media activites\" to further reduce the impurity of the classifications. We can treat this factor as an intermediary step to be factored early in the process to remove True Positives.\n",
        "\n",
        "This leads to a next interesting feature to study. The motivation behind the **political bias** is the hypothesis that the articles that are neutral (or centrist) have higher probability of being truthful compare to articles that are to the far ends of the spectrums (either right-wing or left-wing). Compared to event coverage, I believe political bias as a factor has a greater impact on determining whether the article is fake or not.\n",
        "\n",
        "<img src=\"https://images.pexels.com/photos/1327218/pexels-photo-1327218.jpeg?cs=srgb&dl=alone-casual-couch-1327218.jpg&fm=jpg\" width=200px>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psDhy-9WFWQr",
        "colab_type": "text"
      },
      "source": [
        "### 1.4 Definitions\n",
        "\n",
        "We shall define the  following terms as follows:\n",
        "\n",
        "* **coverage**  - number of news from media outlet that covered the same event or latent topic depicted in the article, within a fixed time window. There is a fixed window of time 1 month (coverage 30) and 2 months (coverage 60) before and after the article was published.\n",
        "\n",
        "* **political bias** - is a rubric indicating a range from 0 to 3 where 0 is centrist affiliation and 3 is left-most or right-most affiliation. Alternative model would be -10 indicating the left-most affiliation and 10 being the right-most affiliation. We simply rectify this model and only work in the range (0 to 10) with 10 being most politically biased (partisan).\n",
        "\n",
        "| 0 | 1 | 2 | 3 |\n",
        "| -- | -- | -- | -- |\n",
        "| Centrist/Neural | Slightly Partisan | Partisan | Strongly Partisan |\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIM_ME3FGXtE",
        "colab_type": "text"
      },
      "source": [
        "### 1.5  Scope\n",
        "\n",
        "To summarize the document will focus on:\n",
        "\n",
        "1. Introduction\n",
        "2. Methods and Approaches\n",
        "3. Importing Data including Data Enrichment\n",
        "4. Other Preliminary Requirements\n",
        "5. Distillation Function Code Reuse and Refactored Code\n",
        "6. Topic Modeling and LDA Analysis\n",
        "7. New Coverage Factor using Word2Vec and Random Forrest Classifier\n",
        "8. Political Spectrum using TF-IDF and Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rvymjHO_TO-",
        "colab_type": "text"
      },
      "source": [
        "### 1.6 Estimated Run time (GPU)\n",
        "\n",
        "- Sections  1 ~ 7 : 40 minutes\n",
        "- Secttion 8: 10 ~ 20 minutes\n",
        "- Section 9: ~ 30 minutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yFjOimJFYA0",
        "colab_type": "text"
      },
      "source": [
        "## 2 Method\n",
        "  \n",
        " After the necessary distillation , the goal is to create approximate scores for recency and political spectrum. \n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chJbzhJcFciq",
        "colab_type": "text"
      },
      "source": [
        " ### 2.1 News Coverage\n",
        " * **Coverage** We first use topic modeling to find the key latent topics. Then we use a separate dataset called \"All the news\" dataset to see if there are other  articles covering a similar event. It is important to note that we are *not* cross-checking factual claims made in the article, but rather checking to see if a related and latent topic can be found in other news sources. If there are no external coverage for the event/topic, chances are that the article in question is likely a fake news. However, just because there are sufficient coverage during the time frame, it does not necessarily mean that the news is completely reliable.\n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLwmYuWaFefL",
        "colab_type": "text"
      },
      "source": [
        "### 2.2 Political Spectrum\n",
        "\n",
        "* **Political spectrum**  Use enrichment dataset. Downlaod a dataset that maps texts to political bias. It is important to note that the spectrum ranges from neutral to partisan (not democratic to republican) as political views can be multipolar comprised of more than two views on the subject. Neutral view would be an objective and fair assessment of the subject discussed. A partisan view is a view that is backed by political ideology, agenda, or combination of both.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSJ18x01FgFv",
        "colab_type": "text"
      },
      "source": [
        "### 2.3 Alternative Methods Tried\n",
        "\n",
        "I have explored NewsAPI which provdes a limited access to its internal databases. NewsAPI in particular allows you to provide a search keywords, and it gives you the relevant news articles related to that keywords. I have created an account with NewsAPI, but soon realized based on the calulations, the rate limiting policy of the API would not allow my ML project to complete in a reasonable time. Thefore, instead of using an API, I decided to download a new dataset from Kaggle (See Section 3.3)\n",
        "\n",
        "* NewsAPI https://newsapi.org/\n",
        "* Google Trends API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOlkr5a4XBUY",
        "colab_type": "text"
      },
      "source": [
        "## 3 Data Preprataions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpgjGVAEFmk7",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 Main Dataset\n",
        "\n",
        "For the purpose of this study, we will focus on the Kaggle's Liar Dataset (Risdal, 2016) The main benefit of Kaggle's Liar Dataset is the text entry that is included with the headline.\n",
        "\n",
        "https://github.com/synle/machine-learning-sample-dataset/raw/master/liar_dataset/kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYIT0KZXFpSl",
        "colab_type": "text"
      },
      "source": [
        "### 3.2 Code For Downloading and Distillation\n",
        "\n",
        "The code for downloading dataset and distillation. written by other team members from the last week, are borrowed, and refactored for the purposes of this week's assignment. While same distillation functions can be applied for most features, it is best to customize it and tailor it to the needs of the two features covered in this portion of the assignment.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQ937__JFq8k",
        "colab_type": "text"
      },
      "source": [
        "### 3.3 Data Enrichment\n",
        "\n",
        "We have use two main datasets to be used for data enrichment:\n",
        "\n",
        "<b>Dataset 1</b> - All The News (Thompson, 2017)\n",
        "- Original: https://www.kaggle.com/snapcrack/all-the-news\n",
        "- Copy: https://github.com/h7shin/all_news_dataset_kaggle\n",
        "\n",
        "The above data is useful for analyzing coverage report of non-fake news articles\n",
        "curated from mainstream news media sites.\n",
        "\n",
        "<b>Dataset 2</b> - Political Social Media Posts (Eight, 2016).\n",
        "- Original: https://www.kaggle.com/crowdflower/political-social-media-posts\n",
        "- Copy: https://github.com/h7shin/political_social_media\n",
        "\n",
        "The above data is useful to identify bag of words translated to the\n",
        "political spectrum."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKTkSKmvt4pZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a6704adc-70a3-4fb6-a6aa-ad0b476100d5"
      },
      "source": [
        "# For caculating approximate time to process notebook (IGNORE)\n",
        "import datetime\n",
        "datetime.datetime.now()"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datetime.datetime(2020, 4, 26, 9, 49, 7, 599381)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXvjp972fR4U",
        "colab_type": "text"
      },
      "source": [
        "## 4 Preliminary Requirements\n",
        "\n",
        "We will leverage some algorithms that have been created by our group members (Sy Le and others) from last week's homework, especially with regards to the distillation. The implementation are refactored and tailored to the needs of this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbtKyhjPZPJn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "0d0694a1-ba2a-4c04-940a-dcd95bc9b8f9"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import io\n",
        "import requests\n",
        "import re\n",
        "\n",
        "# download nltk stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def get_parsed_data(url, sep='\\t', header=None ):\n",
        "  return pd.read_csv(io.StringIO(requests.get(url).content.decode('utf-8')), sep=sep, header=header )\n",
        "\n",
        "# Download and parse the dataset... Let us first work with 100 articles\n",
        "KAGGLE_DATASET = 'https://github.com/synle/machine-learning-sample-dataset/raw/master/liar_dataset/kaggle'\n",
        "data_kaggle = get_parsed_data('%s/kaggle-fake.csv'% KAGGLE_DATASET, ',' , 'infer' )[:1000]\n"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b71vANUdD3Wu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "61778713-2ddc-46db-dd7d-adcda2dc069c"
      },
      "source": [
        "data_kaggle.head(1)"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uuid</th>\n",
              "      <th>ord_in_thread</th>\n",
              "      <th>author</th>\n",
              "      <th>published</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>language</th>\n",
              "      <th>crawled</th>\n",
              "      <th>site_url</th>\n",
              "      <th>country</th>\n",
              "      <th>domain_rank</th>\n",
              "      <th>thread_title</th>\n",
              "      <th>spam_score</th>\n",
              "      <th>main_img_url</th>\n",
              "      <th>replies_count</th>\n",
              "      <th>participants_count</th>\n",
              "      <th>likes</th>\n",
              "      <th>comments</th>\n",
              "      <th>shares</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6a175f46bcd24d39b3e962ad0f29936721db70db</td>\n",
              "      <td>0</td>\n",
              "      <td>Barracuda Brigade</td>\n",
              "      <td>2016-10-26T21:41:00.000+03:00</td>\n",
              "      <td>Muslims BUSTED: They Stole Millions In Gov’t B...</td>\n",
              "      <td>Print They should pay all the back all the mon...</td>\n",
              "      <td>english</td>\n",
              "      <td>2016-10-27T01:49:27.168+03:00</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>US</td>\n",
              "      <td>25689.0</td>\n",
              "      <td>Muslims BUSTED: They Stole Millions In Gov’t B...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>bias</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       uuid  ord_in_thread  ... shares  type\n",
              "0  6a175f46bcd24d39b3e962ad0f29936721db70db              0  ...      0  bias\n",
              "\n",
              "[1 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl8tguc6Fz0T",
        "colab_type": "text"
      },
      "source": [
        "## 5 Distillation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0aPcu4lD26_",
        "colab_type": "text"
      },
      "source": [
        "### 5.1 Tokenization\n",
        "\n",
        "As part of the distillation, we tokenize the headline and the body of the articles, by the following methods. First the words are split based on the white space. We also use this step to combine the title with the body of the article.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFMX9n-AvUdB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "4e569ed7-a13f-4732-9991-d21e1ec8a396"
      },
      "source": [
        "data_kaggle['text_distilled'] = data_kaggle['title'].apply(lambda x : re.split('\\W+', str(x).lower())) +\\\n",
        "   data_kaggle['text'].apply(lambda x : re.split('\\W+', str(x).lower()))\n",
        "data_kaggle.head(1)"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uuid</th>\n",
              "      <th>ord_in_thread</th>\n",
              "      <th>author</th>\n",
              "      <th>published</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>language</th>\n",
              "      <th>crawled</th>\n",
              "      <th>site_url</th>\n",
              "      <th>country</th>\n",
              "      <th>domain_rank</th>\n",
              "      <th>thread_title</th>\n",
              "      <th>spam_score</th>\n",
              "      <th>main_img_url</th>\n",
              "      <th>replies_count</th>\n",
              "      <th>participants_count</th>\n",
              "      <th>likes</th>\n",
              "      <th>comments</th>\n",
              "      <th>shares</th>\n",
              "      <th>type</th>\n",
              "      <th>text_distilled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6a175f46bcd24d39b3e962ad0f29936721db70db</td>\n",
              "      <td>0</td>\n",
              "      <td>Barracuda Brigade</td>\n",
              "      <td>2016-10-26T21:41:00.000+03:00</td>\n",
              "      <td>Muslims BUSTED: They Stole Millions In Gov’t B...</td>\n",
              "      <td>Print They should pay all the back all the mon...</td>\n",
              "      <td>english</td>\n",
              "      <td>2016-10-27T01:49:27.168+03:00</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>US</td>\n",
              "      <td>25689.0</td>\n",
              "      <td>Muslims BUSTED: They Stole Millions In Gov’t B...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>bias</td>\n",
              "      <td>[muslims, busted, they, stole, millions, in, g...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       uuid  ...                                     text_distilled\n",
              "0  6a175f46bcd24d39b3e962ad0f29936721db70db  ...  [muslims, busted, they, stole, millions, in, g...\n",
              "\n",
              "[1 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwTbLXScyNPI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "99d61111-40b3-4719-bb28-000d298588fb"
      },
      "source": [
        "data_kaggle.text_distilled[0][:25]"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['muslims',\n",
              " 'busted',\n",
              " 'they',\n",
              " 'stole',\n",
              " 'millions',\n",
              " 'in',\n",
              " 'gov',\n",
              " 't',\n",
              " 'benefits',\n",
              " 'print',\n",
              " 'they',\n",
              " 'should',\n",
              " 'pay',\n",
              " 'all',\n",
              " 'the',\n",
              " 'back',\n",
              " 'all',\n",
              " 'the',\n",
              " 'money',\n",
              " 'plus',\n",
              " 'interest',\n",
              " 'the',\n",
              " 'entire',\n",
              " 'family',\n",
              " 'and']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9zg6DzVyV1Q",
        "colab_type": "text"
      },
      "source": [
        "### 5.2 Lemmatization\n",
        "  \n",
        "First, the raw words must be converted to root forms.  The words are converted to their root stems based on the following using lemmaitization. Stemming using nltk.PorterStemmer was used previously, but eventually dropped due to its method of dropping suffixes without correction to the root stem. For example, stemming resulted in non-existent words such as 'plu',  'interest',  'entir',  'famili',  'everyon'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs9YyZ8WygUo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "b656fea9-c08f-47f6-a4e9-cdee38b6ab19"
      },
      "source": [
        "def lemmatize(tokenized_words):\n",
        "  text = [nltk.WordNetLemmatizer().lemmatize(word) for word in tokenized_words]\n",
        "  return text\n",
        "\n",
        "# Commented out per rationale above\n",
        "#def stemming(tokenized_words):\n",
        "#  text = [nltk.PorterStemmer().stem(word) for word in tokenized_words]\n",
        "#  return text\n",
        "\n",
        "data_kaggle['text_distilled_lemma'] = data_kaggle['text_distilled'].apply(lemmatize)\n",
        "data_kaggle.text_distilled[0][:15]"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['muslims',\n",
              " 'busted',\n",
              " 'they',\n",
              " 'stole',\n",
              " 'millions',\n",
              " 'in',\n",
              " 'gov',\n",
              " 't',\n",
              " 'benefits',\n",
              " 'print',\n",
              " 'they',\n",
              " 'should',\n",
              " 'pay',\n",
              " 'all',\n",
              " 'the']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRnq7Orw5sSW",
        "colab_type": "text"
      },
      "source": [
        "### 5.3 Removing Stop words\n",
        "\n",
        "Let us remove stop words, which are absolutely critical in determining keywords indicative of timed event."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7axUBcsp5yXD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "3547c135-78a8-448b-ad9a-73fd2bed3903"
      },
      "source": [
        "english_stopwords = set(stopwords.words('english') + list(punctuation) + [''])\n",
        "\n",
        "def remove_stopwords(tokenized_words):\n",
        "  text = [word for word in tokenized_words if word not in english_stopwords]\n",
        "  return text\n",
        "\n",
        "data_kaggle['text_distilled'] = data_kaggle['text_distilled'].apply(remove_stopwords)\n",
        "data_kaggle.text_distilled[0][:15]"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['muslims',\n",
              " 'busted',\n",
              " 'stole',\n",
              " 'millions',\n",
              " 'gov',\n",
              " 'benefits',\n",
              " 'print',\n",
              " 'pay',\n",
              " 'back',\n",
              " 'money',\n",
              " 'plus',\n",
              " 'interest',\n",
              " 'entire',\n",
              " 'family',\n",
              " 'everyone']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejCglovYHwyb",
        "colab_type": "text"
      },
      "source": [
        "### 5.4 Custom Filtering\n",
        "\n",
        "One or two-letter words from the tokenized words are also removed to further cleanse the raw text. First, two-letter words are chosen one by one (there are roughly 100 to 150 words, plus some common country codes). Each word, is examined whether it is worth keeping. Of course, there are more two-letter words than the whitelist shown below, but many of them (e.g. so, am, it) are already eliminated using stop words. If we build a dictionary of all these non-trivial words that are two-letters long, this will help improve the accuracy of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9ujoC42HwGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "whitelist = set(['ai', 'ax', 'ca', 'eu', 'go', 'io', 'la', 'ox', 'us', 'uk', \n",
        "                 'al', 'ak', 'az', 'ar', 'ca', 'co', 'ct', 'de', 'fl', 'ga', 'hi', \n",
        "                 'id', 'il', 'in', 'ia', 'ks', 'ky', 'la', 'me', 'md', 'ma', 'mi',\n",
        "                 'mn', 'ms', 'mo', 'mt', 'ne', 'nv', 'nh', 'nj', 'nm', 'ny',\n",
        "                 'nc', 'nd', 'oh', 'ok', 'or', 'pa', 'ri', 'sc', 'sd', 'tn',\n",
        "                 'tx', 'ut', 'vt', 'va', 'wa', 'wv', 'wi', 'wy' ])\n",
        "def remove_too_short(tokenized_words):\n",
        "  text = [word for word in tokenized_words if (len(word) >= 3 or word not in whitelist) ]\n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iG4ozbF3I_gb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "f7d3124d-496b-4414-a8e0-570900eb3044"
      },
      "source": [
        "data_kaggle['text_distilled'] = data_kaggle['text_distilled'].apply(remove_too_short)\n",
        "data_kaggle.text_distilled[0][:15]"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['muslims',\n",
              " 'busted',\n",
              " 'stole',\n",
              " 'millions',\n",
              " 'gov',\n",
              " 'benefits',\n",
              " 'print',\n",
              " 'pay',\n",
              " 'back',\n",
              " 'money',\n",
              " 'plus',\n",
              " 'interest',\n",
              " 'entire',\n",
              " 'family',\n",
              " 'everyone']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJZExfZ4F5DY",
        "colab_type": "text"
      },
      "source": [
        "## 6 Topic Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGmEhyrkC0e5",
        "colab_type": "text"
      },
      "source": [
        "### 6.1 LDA Analysis\n",
        "Relevant Assignment Requirement 2(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IUeTqEPEWLz",
        "colab_type": "text"
      },
      "source": [
        "We will use topic modelling (LDA) to identify the key topics, \n",
        "https://towardsdatascience.com/topic-modelling-in-python-with-nltk-and-gensim-4ef03213cd21\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMZcdhA7E0Rv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "a171dd52-5fae-4999-df99-54de864f7eb8"
      },
      "source": [
        "! pip install gensim"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.3)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.21.0)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.12.43)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.5)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.43 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.15.43)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->smart-open>=1.2.1->gensim) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7Fdvch1EjQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models.ldamodel import LdaModel\n",
        "from gensim.corpora import Dictionary\n",
        "\n",
        "def topics(tokenized_words):\n",
        "    d = Dictionary([tokenized_words])\n",
        "    c = [d.doc2bow(tokenized_words)]\n",
        "    m = LdaModel(c, num_topics=1, id2word=d)\n",
        "    return list(m.print_topics(num_words=2))\n",
        "  \n",
        "data_kaggle['topics'] = data_kaggle['text_distilled'].apply(topics)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2_6vpztHdgn",
        "colab_type": "text"
      },
      "source": [
        "Let us analyze the topics of some sample articles:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYd-SH8nHhOI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e4685213-cdf8-4b7b-fd49-ad45824ff8e0"
      },
      "source": [
        "data_kaggle.title[1],data_kaggle.topics[1]"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Re: Why Did Attorney General Loretta Lynch Plead The Fifth?',\n",
              " [(0, '0.033*\"lynch\" + 0.020*\"attorney\"')])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbXOFnFFHlMX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3da0f26d-d1af-433b-f98d-18b4a5592aab"
      },
      "source": [
        "data_kaggle.title[2],data_kaggle.topics[3]"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('BREAKING: Weiner Cooperating With FBI On Hillary Email Investigation',\n",
              " [(0, '0.049*\"speech\" + 0.037*\"donald\"')])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtorWr60Hndl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "997227b2-0db2-4e3f-c25c-af59b897fdac"
      },
      "source": [
        "data_kaggle.title[3],data_kaggle.topics[3]"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnapped And Killed By ISIS: \"I have voted for Donald J. Trump!\" » 100percentfedUp.com',\n",
              " [(0, '0.049*\"speech\" + 0.037*\"donald\"')])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVo-d0S6H_Q5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f1d50c83-3c23-4516-dbb3-7824ce3fe6b2"
      },
      "source": [
        "data_kaggle.title[4],data_kaggle.topics[4]"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Healthcare Begins With A Bombshell! » 100percentfedUp.com\",\n",
              " [(0, '0.022*\"insurance\" + 0.016*\"must\"')])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsAmtH0abASA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2ca1b7d-6e3c-4a18-ccf7-2cc98f143c4a"
      },
      "source": [
        "len(data_kaggle.title)"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze4YTpBLultl",
        "colab_type": "text"
      },
      "source": [
        "### 6.2 Topics as Simple List of Words\n",
        "\n",
        "A list of topic terms is compiled as show below. The coefficients in front of each word are dropped as part of simplification. The assumption is that the top two words comprising the topic, are both significant enough to be treated equally. It is important that the goal is to build a reliable prediction model. While there is a risk of oversimplification, if the final model results in a poor accuracy score, the coefficient can always be reintroduced here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1fxmdcyuqoB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parseTopics(topics):\n",
        "   output = []\n",
        "   words = topics[0][1].split( '+' )\n",
        "   for word in words:\n",
        "       output.append( word.split('*')[1].replace( '\"', '' ) )\n",
        "   return output\n",
        "\n",
        "data_kaggle['topics'] = data_kaggle['topics'].apply(parseTopics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea1LjWkvyjGg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "63e09280-1e1c-492e-a89b-c6288de2dcef"
      },
      "source": [
        "data_kaggle.title[1],data_kaggle.topics[1]"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Re: Why Did Attorney General Loretta Lynch Plead The Fifth?',\n",
              " ['lynch ', 'attorney'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF7YvJWHF76L",
        "colab_type": "text"
      },
      "source": [
        "## 7 Coverage Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zphchkmJTFm",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "### 7.1 Data Enrichment\n",
        "\n",
        "The notebook uses Kaggle's \"All the news\" dataset to curate reference articles to enrich the study of coverage analysis  (Thompson,  2017).\n",
        "\n",
        "<img src=\"https://images.pexels.com/photos/261949/pexels-photo-261949.jpeg?cs=srgb&dl=administration-articles-bank-261949.jpg&fm=jpg\" width=400px>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvdThmnzJYcw",
        "colab_type": "text"
      },
      "source": [
        "The relevant dataset files are downloaded from Kaggle, unzipped and re-uploaded to GitHub repository (Thompson,  2017).\n",
        "\n",
        "https://www.kaggle.com/snapcrack/all-the-news/home\n",
        "\n",
        "```\n",
        "dock2 ~/wses/all_news_dataset_kaggle$ unzip articles1.csv.zip\n",
        "Archive:  articles1.csv.zip\n",
        "  inflating: articles1.csv\n",
        "dock2 ~/wses/all_news_dataset_kaggle$ unzip articles2.csv.zip\n",
        "Archive:  articles2.csv.zip\n",
        "  inflating: articles2.csv\n",
        "dock2 ~/wses/all_news_dataset_kaggle$ unzip articles3.csv.zip\n",
        "Archive:  articles3.csv.zip\n",
        "  inflating: articles3.csv\n",
        "```\n",
        "\n",
        "The csv files are almost 200MB in size. Therefore, we must treat them differently before uploading to GitHub.\n",
        "\n",
        "```\n",
        "dock2 ~/wses/all_news_dataset_kaggle$ git lfs track *.csv\n",
        "\"articles1.csv\" already supported\n",
        "\"articles2.csv\" already supported\n",
        "\"articles3.csv\" already supported\n",
        "...\n",
        "dock2 ~/wses/all_news_dataset_kaggle$ git remote add origin git@github.com:h7shin/all_news_dataset_kaggle.git\n",
        "...\n",
        "dock2 ~/wses/all_news_dataset_kaggle$ git push -u origin master\n",
        "Uploading LFS objects:   0% (0/1), 54 MB | 4.5 MB/s\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2-jg47QJw-E",
        "colab_type": "text"
      },
      "source": [
        "Since \"articles1.csv\" was sufficient to get a good coverage analysis. The data from articles2.csv and articles3.csv were dropped. Including all data unnecesarily, can result in slow distillation, training and testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY_V-_aIqVcA",
        "colab_type": "text"
      },
      "source": [
        "Verifying that the above dataset is downloaded successfully, `all_data_kaggle_1.head()` was called."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtEk_PmgNsvy",
        "colab_type": "text"
      },
      "source": [
        "All three data frames could be consolidated, but since only the first csv file (and its corresponding data frame all_kaggle1) was used, there is no need to combine them any longer,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvF20LRi4gC3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "1d51d75a-2343-40a7-afad-7cb38aa568c0"
      },
      "source": [
        "# All News Kaggle\n",
        "\n",
        "def get_parsed_data2(url):\n",
        "    return pd.read_csv(io.StringIO(requests.get(url, verify=False).content.decode('utf-8')), sep=',', header='infer')\n",
        "\n",
        "# download and parse the dataset...\n",
        "all_kaggle = get_parsed_data2('https://media.githubusercontent.com/media/hyunwookshin/all_news_dataset_kaggle/master/articles1.csv')"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po0XsMLYfajj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#all_kaggle = pd.read_csv('/content/drive/My Drive/Colab Notebooks/articles1.csv', low_memory =False, encoding = \"ISO-8859-1\")\n",
        "#all_kaggle.head(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhQ-IF-zOUO0",
        "colab_type": "text"
      },
      "source": [
        "### 7.3 Cleansing \"All News\" Articles and Finding Document Similarity\n",
        "\n",
        "For each article, the goal is to count all relevant articles in the all_kaggle dataset that contain similar topics. To achieve this, we also need to do a latent topic modelling.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9l9rOTXKamH",
        "colab_type": "text"
      },
      "source": [
        "### 7.4 Distillation - Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbO7ZLO1YH4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_kaggle['text_distilled'] = all_kaggle['title'].apply(lambda x : re.split('\\W+', str(x).lower())) +\\\n",
        "   all_kaggle['content'].apply(lambda x : re.split('\\W+', str(x).lower()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9irzj0FZEhF",
        "colab_type": "text"
      },
      "source": [
        "### 7.5 Distillation - Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAfdciGTZI1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_kaggle['text_distilled'] = all_kaggle['text_distilled'].apply(lemmatize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grYBujqWZOq6",
        "colab_type": "text"
      },
      "source": [
        "### 7.6 Distillation - Stop Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gX8qfbHaZQs7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_kaggle['text_distilled'] = all_kaggle['text_distilled'].apply(remove_stopwords)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gY0-N4QcZVZg",
        "colab_type": "text"
      },
      "source": [
        "### 7.7 Distillation - Additional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE_D_lRwZeFS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "1980e8a0-c1f7-4fda-fe04-118644edec84"
      },
      "source": [
        "all_kaggle['text_distilled'] = all_kaggle['text_distilled'].apply(remove_too_short)\n",
        "all_kaggle.text_distilled[0][:15]"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['house',\n",
              " 'republican',\n",
              " 'fret',\n",
              " 'winning',\n",
              " 'health',\n",
              " 'care',\n",
              " 'suit',\n",
              " 'new',\n",
              " 'york',\n",
              " 'time',\n",
              " 'washington',\n",
              " 'congressional',\n",
              " 'republican',\n",
              " 'new',\n",
              " 'fear']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3-ov1YYh0T7",
        "colab_type": "text"
      },
      "source": [
        "### 7.8 Distillation - Topic Analysis - Running LDA to Extract Topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXE5jGJch3Sl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_kaggle['topics'] = all_kaggle['text_distilled'].apply(topics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-X6lPwwzFKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_kaggle['topics'] = all_kaggle['topics'].apply(parseTopics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2i5bFLlWooh9",
        "colab_type": "text"
      },
      "source": [
        "Making sure that the distillation is succesful, the following snippet was run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJiv4v0o1Nds",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "12232406-8e2d-485e-9a0f-34b7ad2c9aae"
      },
      "source": [
        "all_kaggle.title[0], all_kaggle.topics[0]"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('House Republicans Fret About Winning Their Health Care Suit - The New York Times',\n",
              " ['house ', 'republican'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niepPGo74ydv",
        "colab_type": "text"
      },
      "source": [
        "### 7.9 Scoring Coverage (Ranking)\n",
        "\n",
        "The latent topics are parsed from non-fake news datset. To make an appropriate scoring coverage, the latent topics between \"all news\" data set and fake news dataset (`data_kaggle`) are compared."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2AldcftKUOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def setDate( published ):\n",
        "   return published.split( \"T\" )[0]\n",
        "\n",
        "data_kaggle[ 'date' ] = data_kaggle.published.apply( setDate )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmUHDODsMss4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "4f4a7d5f-a6b6-42fd-9006-a1d87b984cab"
      },
      "source": [
        "data_kaggle.head(1)"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uuid</th>\n",
              "      <th>ord_in_thread</th>\n",
              "      <th>author</th>\n",
              "      <th>published</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>language</th>\n",
              "      <th>crawled</th>\n",
              "      <th>site_url</th>\n",
              "      <th>country</th>\n",
              "      <th>domain_rank</th>\n",
              "      <th>thread_title</th>\n",
              "      <th>spam_score</th>\n",
              "      <th>main_img_url</th>\n",
              "      <th>replies_count</th>\n",
              "      <th>participants_count</th>\n",
              "      <th>likes</th>\n",
              "      <th>comments</th>\n",
              "      <th>shares</th>\n",
              "      <th>type</th>\n",
              "      <th>text_distilled</th>\n",
              "      <th>text_distilled_lemma</th>\n",
              "      <th>topics</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6a175f46bcd24d39b3e962ad0f29936721db70db</td>\n",
              "      <td>0</td>\n",
              "      <td>Barracuda Brigade</td>\n",
              "      <td>2016-10-26T21:41:00.000+03:00</td>\n",
              "      <td>Muslims BUSTED: They Stole Millions In Gov’t B...</td>\n",
              "      <td>Print They should pay all the back all the mon...</td>\n",
              "      <td>english</td>\n",
              "      <td>2016-10-27T01:49:27.168+03:00</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>US</td>\n",
              "      <td>25689.0</td>\n",
              "      <td>Muslims BUSTED: They Stole Millions In Gov’t B...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>bias</td>\n",
              "      <td>[muslims, busted, stole, millions, gov, benefi...</td>\n",
              "      <td>[muslim, busted, they, stole, million, in, gov...</td>\n",
              "      <td>[benefits , government]</td>\n",
              "      <td>2016-10-26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       uuid  ...        date\n",
              "0  6a175f46bcd24d39b3e962ad0f29936721db70db  ...  2016-10-26\n",
              "\n",
              "[1 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUkP6m52K1bm",
        "colab_type": "text"
      },
      "source": [
        "The coverage window is simply a time-range where two articles are considered to be pushed in the same approximate \"time frame\". Narrowing the window size will result in low coverage score across all rows. Increasing the window size will result in high coverage score across all rows. The choice of the window size was arbitrary (30 days). Please see section 7.17 for 60-day coverage window."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7lBooYW_G73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "\n",
        "def window( datestring, n ):\n",
        "   d = datetime.datetime.strptime( datestring, \"%Y-%m-%d\" )\n",
        "   delta = datetime.timedelta(days=n)\n",
        "   fromdate = datetime.datetime.strftime(d - delta, \"%Y-%m-%d\")\n",
        "   todate = datetime.datetime.strftime(d + delta, \"%Y-%m-%d\")\n",
        "   return ( fromdate, todate )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7E8BzmwZwzy",
        "colab_type": "text"
      },
      "source": [
        "Please note that coverage scoring below can take about 10~15 minutes to complete (With GPU Hardware accelerator)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rf0YsfVr4-sj",
        "colab_type": "code",
        "outputId": "6abf1ac8-05cb-4853-8143-8e3477bf9558",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "import datetime\n",
        "\n",
        "print( \"Start Time\", datetime.datetime.now() )\n",
        "\n",
        "def coverage( article ):\n",
        "   fromdate, todate = window( article[ 'date' ], 15 )\n",
        "   selected_coverage = all_kaggle[(all_kaggle['date'] > fromdate) & (all_kaggle['date'] < todate)]\n",
        "   selected_coverage['covered'] = selected_coverage.apply( lambda r: r[ 'topics' ][0] in article.topics and\n",
        "                                                       r[ 'topics' ][1] in article.topics, axis=1 )\n",
        "   return len(selected_coverage[selected_coverage['covered'] == True])\n",
        "\n",
        "data_kaggle[ 'coverage' ] = data_kaggle.apply( coverage, axis=1 )\n",
        "\n",
        "print( \"Finished Time\", datetime.datetime.now() )"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start Time 2020-04-26 09:53:30.842635\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Time 2020-04-26 09:54:50.505867\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xSxz3uSSR0l",
        "colab_type": "code",
        "outputId": "5d289a67-9bd7-4f07-a084-7bd89db6c0bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        }
      },
      "source": [
        "data_kaggle.sort_values(by=['coverage'], ascending=False ).head(5)"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uuid</th>\n",
              "      <th>ord_in_thread</th>\n",
              "      <th>author</th>\n",
              "      <th>published</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>language</th>\n",
              "      <th>crawled</th>\n",
              "      <th>site_url</th>\n",
              "      <th>country</th>\n",
              "      <th>domain_rank</th>\n",
              "      <th>thread_title</th>\n",
              "      <th>spam_score</th>\n",
              "      <th>main_img_url</th>\n",
              "      <th>replies_count</th>\n",
              "      <th>participants_count</th>\n",
              "      <th>likes</th>\n",
              "      <th>comments</th>\n",
              "      <th>shares</th>\n",
              "      <th>type</th>\n",
              "      <th>text_distilled</th>\n",
              "      <th>text_distilled_lemma</th>\n",
              "      <th>topics</th>\n",
              "      <th>date</th>\n",
              "      <th>coverage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>a36405a8d7d32c2192b9a9b482dcf0ebc83c62eb</td>\n",
              "      <td>0</td>\n",
              "      <td>Mike Rivero</td>\n",
              "      <td>2016-11-23T00:49:00.000+02:00</td>\n",
              "      <td>FLASHBACK - Hillary Clinton’s ‘KKK’ Smear Agai...</td>\n",
              "      <td>November 21, 2016 By 21wire Leave a Comment \\n...</td>\n",
              "      <td>english</td>\n",
              "      <td>2016-11-23T01:36:58.899+02:00</td>\n",
              "      <td>21stcenturywire.com</td>\n",
              "      <td>US</td>\n",
              "      <td>NaN</td>\n",
              "      <td>FLASHBACK - Hillary Clinton’s ‘KKK’ Smear Agai...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>http://i2.wp.com/21stcenturywire.com/wp-conten...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>conspiracy</td>\n",
              "      <td>[flashback, hillary, clinton, kkk, smear, trum...</td>\n",
              "      <td>[flashback, hillary, clinton, s, kkk, smear, a...</td>\n",
              "      <td>[mr , trump]</td>\n",
              "      <td>2016-11-23</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>c1a86b752a21196a06591d5a785fa29b14fab245</td>\n",
              "      <td>0</td>\n",
              "      <td>EdJenner</td>\n",
              "      <td>2016-11-22T08:17:53.961+02:00</td>\n",
              "      <td>DONALD TRUMP Calls Meeting With Press…Dresses ...</td>\n",
              "      <td>Go to Article \\nThey had to know they had it c...</td>\n",
              "      <td>english</td>\n",
              "      <td>2016-11-22T08:17:53.961+02:00</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>US</td>\n",
              "      <td>25689.0</td>\n",
              "      <td>DONALD TRUMP Calls Meeting With Press…Dresses ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>http://conservativeangle.com/wp-content/upload...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>bias</td>\n",
              "      <td>[donald, trump, calls, meeting, press, dresses...</td>\n",
              "      <td>[donald, trump, call, meeting, with, press, dr...</td>\n",
              "      <td>[trump , said]</td>\n",
              "      <td>2016-11-22</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>959</th>\n",
              "      <td>62a33ca2aa94dede5212714fd0d31ffb3ee089e1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2016-10-27T21:14:42.443+03:00</td>\n",
              "      <td>Trump warns of World War III if Clinton is ele...</td>\n",
              "      <td>Email Donald Trump warned in an interview Tues...</td>\n",
              "      <td>english</td>\n",
              "      <td>2016-10-27T21:14:42.443+03:00</td>\n",
              "      <td>awdnews.com</td>\n",
              "      <td>DE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Trump warns of World War III if Clinton is ele...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>http://awdnews.com/images/14775862276361308531...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>conspiracy</td>\n",
              "      <td>[trump, warns, world, war, iii, clinton, elect...</td>\n",
              "      <td>[trump, warns, of, world, war, iii, if, clinto...</td>\n",
              "      <td>[trump , clinton]</td>\n",
              "      <td>2016-10-27</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>980</th>\n",
              "      <td>29aa6e6c0aa6e47a2ee80e18b8ddc031657425b0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2016-10-28T18:34:48.985+03:00</td>\n",
              "      <td>FEAR OF TRUMP: BUSH, OBAMA, CLINTON ALL BUYING...</td>\n",
              "      <td>Email \\n\\nIt appears Bill and Hillary Clinton ...</td>\n",
              "      <td>english</td>\n",
              "      <td>2016-10-28T18:34:48.985+03:00</td>\n",
              "      <td>awdnews.com</td>\n",
              "      <td>DE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>FEAR OF TRUMP: BUSH, OBAMA, CLINTON ALL BUYING...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>http://awdnews.com/images/14776680451.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>conspiracy</td>\n",
              "      <td>[fear, trump, bush, obama, clinton, buying, pr...</td>\n",
              "      <td>[fear, of, trump, bush, obama, clinton, all, b...</td>\n",
              "      <td>[trump , clinton]</td>\n",
              "      <td>2016-10-28</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>988</th>\n",
              "      <td>b2e81b8debd3ca29f942d34b781126c07e427194</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2016-10-28T18:40:18.626+03:00</td>\n",
              "      <td>FEAR OF TRUMP: BUSH, OBAMA, CLINTON ALL BUYING...</td>\n",
              "      <td>Email \\n\\nIt appears Bill and Hillary Clinton ...</td>\n",
              "      <td>english</td>\n",
              "      <td>2016-10-28T18:40:18.626+03:00</td>\n",
              "      <td>awdnews.com</td>\n",
              "      <td>DE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>FEAR OF TRUMP: BUSH, OBAMA, CLINTON ALL BUYING...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>http://awdnews.com/images/14776680451.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>conspiracy</td>\n",
              "      <td>[fear, trump, bush, obama, clinton, buying, pr...</td>\n",
              "      <td>[fear, of, trump, bush, obama, clinton, all, b...</td>\n",
              "      <td>[trump , clinton]</td>\n",
              "      <td>2016-10-28</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         uuid  ...  coverage\n",
              "53   a36405a8d7d32c2192b9a9b482dcf0ebc83c62eb  ...        41\n",
              "26   c1a86b752a21196a06591d5a785fa29b14fab245  ...        23\n",
              "959  62a33ca2aa94dede5212714fd0d31ffb3ee089e1  ...        23\n",
              "980  29aa6e6c0aa6e47a2ee80e18b8ddc031657425b0  ...        21\n",
              "988  b2e81b8debd3ca29f942d34b781126c07e427194  ...        21\n",
              "\n",
              "[5 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwZBsbTCUZVW",
        "colab_type": "code",
        "outputId": "4e211ef8-c8c6-4a3e-da18-a5aa0a952673",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "data_kaggle.sort_values(by=['coverage'], ascending=False ).head(1)['title'], data_kaggle.sort_values(by=['coverage'], ascending=False ).head(1)['coverage']"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(53    FLASHBACK - Hillary Clinton’s ‘KKK’ Smear Agai...\n",
              " Name: title, dtype: object, 53    41\n",
              " Name: coverage, dtype: int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYppcAHMCJTg",
        "colab_type": "text"
      },
      "source": [
        "### 7.10 Intermediary Analysis\n",
        "\n",
        "**Label Pairing** - For now,  top two words of the topics are chosen in the all-news dataset, as \"labels.\" Then using the topics of each fake news datasets and number all-news articles corresponding to each fake news article can be deduced. This means that for every article, we are searching for related articles. \n",
        "\n",
        "<i>Hypothetical Label Pairing for Illustration Purposes</i>\n",
        "\n",
        "Table A (10 articles)\n",
        "\n",
        "|  Articles | Topic Words | Computed Coverage Score | Rationale |\n",
        "| -- | -- | -- |\n",
        "|  1            | \"Apple\", \"Banana\" | 0 | Matches None from B |\n",
        "|  2            | \"Apple\", \"Orange\" | 1 |  Matches B.2 |\n",
        "|  3            | \"Orange\", \"Pear\" | 2 | Matches B.3 and B.1023 | \n",
        "| ... | ... |\n",
        "\n",
        "Table B (10,000 articles)\n",
        "\n",
        "|  Articles | Topic Words |\n",
        "| -- | -- |\n",
        "|  1            | \"Apple\", \"Pear\" |\n",
        "|  2            | \"Apple\", \"Orange\" |\n",
        "|  3            | \"Orange\", \"Pear\" |\n",
        "| ... | ... |\n",
        "|  1023      | \"Orange\", \"Pear\" |\n",
        "| ... | ... | \n",
        "\n",
        "**Building a Model** This \"search\" part should only be done during training stage, but not during testing and validation stages. But manually searching each row in the database is expensive and unscalable. Also, if the model simply looks up in internal database and return the score, it is more or less a search solution, not a Machine Learning Classification solution.\n",
        "\n",
        "Instead of doing this search for every article, the model should predict how much coverage it is likely to have based on the top two **topic terms** and the **date** of publication with classifiers such as Naive Bayes or Decision Trees. Clearly it will require lot of articles for training since there will be a rich set of topic terms and dates resulting in wide range of coverage scores.\n",
        "\n",
        "**Risks** There is some risk involved with this approach. Sometimes LDA and topic modeliing doesn't get us far enough. Sometimes the keywords generated by LDA such as \"Car\", \"Bus\", \"Train\" all have the latent super-topic called \"transporation\".  So in our distillation not only we should filter out stop words and run lemmatization, we should condense the words even further such as \"transportation\".  This will require additional data enrichment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqBDT4GRSfzk",
        "colab_type": "text"
      },
      "source": [
        "### 7.11 Using word2vec to Convert Topics to Vector Embeddings\n",
        "\n",
        "We use word2vec to fit the entire text from all articles, and then use word2vec model to convert the topic words to vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvYioQTYX45d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "m = Word2Vec( data_kaggle[ 'text_distilled' ] )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOm_gT6kX-4n",
        "colab_type": "code",
        "outputId": "10d4bf26-ff45-460b-d927-3f0e97693c01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "m.similarity( 'clinton', 'hillary' )"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.960011"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIkRu0jJDf7O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "2d8d844a-b083-4a91-f6a5-9dae6575354d"
      },
      "source": [
        "m.similarity( 'trump', 'election' )"
      ],
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.42066944"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 298
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xU2GJjca4ne",
        "colab_type": "code",
        "outputId": "eec4f88c-cb79-4b0f-b457-6cf462d756db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def encodeFirstColumn( topics ):\n",
        "   topic = topics[0].strip()\n",
        "   if topic in m:\n",
        "      return m[topic].tolist()\n",
        "   else:\n",
        "      return np.zeros( len(m[list(m.wv.vocab)[0]]) ).tolist()\n",
        "   \n",
        "data_kaggle[ 'topic_0' ] = data_kaggle.topics.apply( encodeFirstColumn )"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7Twt8fwOD9q",
        "colab_type": "text"
      },
      "source": [
        "Running few sanity check, to ensure that the computation is correct,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxVAnQpEeFkK",
        "colab_type": "code",
        "outputId": "fc8bbaff-daf9-4a32-88c9-e8293ccb75f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "'clinton' in m"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmUtOkKddfwx",
        "colab_type": "code",
        "outputId": "0fe9ea1a-f60d-4b63-ba58-0c6bd2393740",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "m['hillary']"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.31879997, -0.22580366, -0.17212008,  0.09874977,  0.24893382,\n",
              "        0.3517544 ,  0.1978371 , -0.7333477 ,  0.612809  ,  0.06544967,\n",
              "        0.54596627,  0.13797599, -0.23982847, -0.18955646,  0.30758926,\n",
              "       -0.59343094, -0.18451451,  0.41555727, -0.3884194 ,  0.249655  ,\n",
              "       -1.1654482 , -0.66507965, -1.4754508 ,  0.7061033 , -0.23800834,\n",
              "       -1.2167997 ,  0.8225049 , -0.60582465, -1.1752366 ,  0.5211791 ,\n",
              "        0.2968905 ,  0.6069956 ,  0.42035717, -0.47865236, -1.2683598 ,\n",
              "        0.12595356,  0.24861374,  0.74896866, -0.19600643,  0.68728817,\n",
              "        0.40185073,  0.23880985, -0.13062134, -0.27110967, -1.504036  ,\n",
              "        0.9676935 , -0.00403398,  0.08776239,  0.70877993,  1.1538895 ,\n",
              "        0.93511146,  0.331018  ,  0.07987308, -1.8719064 ,  0.39871097,\n",
              "        0.18458289,  1.0057348 , -0.60205436,  0.3454686 , -0.52003264,\n",
              "        0.05029142,  0.81063914,  0.20208396,  0.0168014 , -0.12856883,\n",
              "        0.5638626 ,  0.13729899, -0.5576596 , -0.14867501, -0.2151114 ,\n",
              "       -0.57741785,  0.528263  , -0.8089936 ,  0.12520829,  1.1960458 ,\n",
              "       -0.36625367, -0.5906471 , -0.828653  ,  0.38381377,  0.19112495,\n",
              "       -0.37140906,  0.5957641 , -0.411918  , -0.15333188, -1.1524625 ,\n",
              "       -1.2370919 ,  0.31864303,  1.091761  , -0.0415777 ,  0.4969127 ,\n",
              "       -0.7248516 ,  0.23915657, -0.19603369, -0.30301866,  0.7353967 ,\n",
              "       -0.8609412 ,  0.53946793, -0.28988424,  0.9511596 ,  0.3302992 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2O1Hndddaya",
        "colab_type": "code",
        "outputId": "6275331c-2d6d-4b7c-ca1d-f45135ae2f59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "data_kaggle[ 'topic_0' ][:10]"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [0.21916016936302185, -0.07196341454982758, 0....\n",
              "1    [0.25437697768211365, -0.08556625247001648, 0....\n",
              "2    [0.360089510679245, -0.13637320697307587, 0.28...\n",
              "3    [0.4184187054634094, -0.15810750424861908, 0.3...\n",
              "4    [0.24776127934455872, -0.0960649698972702, 0.2...\n",
              "5    [0.2722969651222229, -0.426133930683136, 0.207...\n",
              "6    [0.22841064631938934, -0.07768463343381882, 0....\n",
              "7    [0.4885796904563904, -0.17945608496665955, 0.3...\n",
              "8    [0.2722969651222229, -0.426133930683136, 0.207...\n",
              "9    [0.48507755994796753, -0.6275070905685425, -0....\n",
              "Name: topic_0, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CR9_HEdIrK4H",
        "colab_type": "code",
        "outputId": "686b36ef-16f4-4127-9341-732a9f8428b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "def assertDim( topic_vec ):\n",
        "   assert len(topic_vec) == len(m[list(m.wv.vocab)[0]]) and len(topic_vec) > 0\n",
        "    \n",
        "def assertType( topic_vec ):\n",
        "   assert isinstance(topic_vec, list)\n",
        "    \n",
        "data_kaggle.topic_0.apply( assertDim )[0]\n",
        "data_kaggle.topic_0.apply( assertType )[0]"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahGoFM6vh7x7",
        "colab_type": "text"
      },
      "source": [
        "The second topic term is also encoded into word2vec vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umXWwTwPh-Cq",
        "colab_type": "code",
        "outputId": "89299069-aea3-4d77-b462-144d422d85b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "vector_dim = len(m[list(m.wv.vocab)[0]])\n",
        "\n",
        "def encodeSecondColumn( topics ):\n",
        "\n",
        "   if len( topics ) > 1 :\n",
        "      topic = topics[1].strip()\n",
        "   else:\n",
        "      return np.zeros( len(m[list(m.wv.vocab)[0]]) ).tolist()\n",
        "   if topic in m:\n",
        "      return m[topic].tolist()\n",
        "   else:\n",
        "      return np.zeros( len(m[list(m.wv.vocab)[0]]) ).tolist()\n",
        "   \n",
        "data_kaggle[ 'topic_1' ] = data_kaggle.topics.apply( encodeSecondColumn )"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sHff2U4rk42",
        "colab_type": "code",
        "outputId": "2204e8cf-c845-467a-b96a-1d484d5634b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "data_kaggle.topic_1.apply( assertDim )[0]\n",
        "data_kaggle.topic_1.apply( assertType )[0]"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJaoPNCgOx35",
        "colab_type": "text"
      },
      "source": [
        "### 7.12 Sentiment Analysis\n",
        "\n",
        "Sentiment analysis has been done on the Kaggle data set, from \n",
        "(Martin et. al, n.d)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZC6SGIW2ynYk",
        "colab_type": "code",
        "outputId": "b86fda97-74fe-4a8b-a519-2786213bd084",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "def getSentiment( text ):\n",
        "    return sia.polarity_scores(text)\n",
        "  \n",
        "data_kaggle[ 'text_distilled_joined' ] = data_kaggle[ 'text_distilled' ].apply( lambda x : ' '.join(x) ) \n",
        "data_kaggle[ 'sentiment' ] = data_kaggle.text_distilled_joined.apply( getSentiment )\n",
        "\n",
        "print(data_kaggle['sentiment' ][:10] )"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "0    {'neg': 0.135, 'neu': 0.669, 'pos': 0.196, 'co...\n",
            "1    {'neg': 0.129, 'neu': 0.815, 'pos': 0.057, 'co...\n",
            "2    {'neg': 0.051, 'neu': 0.791, 'pos': 0.158, 'co...\n",
            "3    {'neg': 0.3, 'neu': 0.46, 'pos': 0.24, 'compou...\n",
            "4    {'neg': 0.093, 'neu': 0.722, 'pos': 0.185, 'co...\n",
            "5    {'neg': 0.356, 'neu': 0.591, 'pos': 0.053, 'co...\n",
            "6    {'neg': 0.135, 'neu': 0.723, 'pos': 0.142, 'co...\n",
            "7    {'neg': 0.193, 'neu': 0.735, 'pos': 0.072, 'co...\n",
            "8    {'neg': 0.066, 'neu': 0.842, 'pos': 0.093, 'co...\n",
            "9    {'neg': 0.152, 'neu': 0.792, 'pos': 0.056, 'co...\n",
            "Name: sentiment, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLbABjp8js1G",
        "colab_type": "text"
      },
      "source": [
        "### 7.13 Converting Dates to Numeric Format\n",
        "\n",
        "The date column with format YYYY-MM-dd is converted into YYYYMM  (where MM is month, and YYYY) is year. Specific day of the months is dropped to avoid overfitting.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moZ3wZ8el_vt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def setNumericDate( date ):\n",
        "   y, m, d = date.split( \"-\" )\n",
        "   return int(y + m)\n",
        "\n",
        "data_kaggle[ 'date_int' ] = data_kaggle.date.apply( setNumericDate )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbTvpmfWqCpa",
        "colab_type": "code",
        "outputId": "aa4665a6-3a4c-4743-8425-0d5fda624113",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_kaggle[ 'date_int' ][0]"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "201610"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpG9THMLn5SM",
        "colab_type": "text"
      },
      "source": [
        "### 7.14 Using Ranfom Forrest Classifier\n",
        "\n",
        "Using the numeric (integer) dates, and two vectors (for top two topics chosen), a random forrest classifier is trained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHN5I6ET38BH",
        "colab_type": "code",
        "outputId": "4f0bcbc0-1c2e-4edd-d014-60b9e3dcbb7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "# First split the vectors of word2vec into individual columns\n",
        "\n",
        "X_prep = data_kaggle[[ 'date_int', 'topic_0', 'topic_1' ]]\n",
        "\n",
        "def select(topic_vec, idx):\n",
        "   return topic_vec[idx]\n",
        "\n",
        "prep_dict = { \"date_int\" : [] }\n",
        "for i in range( vector_dim*2 ):\n",
        "   prep_dict[str(i)] = []\n",
        "    \n",
        "X_COV = pd.DataFrame(prep_dict)\n",
        "X_COV[ 'date_int' ] = X_prep[ 'date_int' ]\n",
        "\n",
        "vector_dim = len(m[list(m.wv.vocab)[0]])\n",
        "\n",
        "for i in range( vector_dim ):\n",
        "   X_COV[str(i)] = X_prep.topic_0.apply( lambda x : select(x, i ) )\n",
        "    \n",
        "X_COV.head(1)"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date_int</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>160</th>\n",
              "      <th>161</th>\n",
              "      <th>162</th>\n",
              "      <th>163</th>\n",
              "      <th>164</th>\n",
              "      <th>165</th>\n",
              "      <th>166</th>\n",
              "      <th>167</th>\n",
              "      <th>168</th>\n",
              "      <th>169</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "      <th>180</th>\n",
              "      <th>181</th>\n",
              "      <th>182</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "      <th>188</th>\n",
              "      <th>189</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>193</th>\n",
              "      <th>194</th>\n",
              "      <th>195</th>\n",
              "      <th>196</th>\n",
              "      <th>197</th>\n",
              "      <th>198</th>\n",
              "      <th>199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>201610</td>\n",
              "      <td>0.21916</td>\n",
              "      <td>-0.071963</td>\n",
              "      <td>0.17161</td>\n",
              "      <td>0.059836</td>\n",
              "      <td>0.112974</td>\n",
              "      <td>0.054606</td>\n",
              "      <td>-0.121356</td>\n",
              "      <td>-0.037751</td>\n",
              "      <td>0.231681</td>\n",
              "      <td>0.143301</td>\n",
              "      <td>-0.083935</td>\n",
              "      <td>-0.000597</td>\n",
              "      <td>-0.102584</td>\n",
              "      <td>-0.223626</td>\n",
              "      <td>0.244886</td>\n",
              "      <td>0.015411</td>\n",
              "      <td>0.009623</td>\n",
              "      <td>0.088618</td>\n",
              "      <td>-0.023797</td>\n",
              "      <td>0.159932</td>\n",
              "      <td>-0.115685</td>\n",
              "      <td>0.073454</td>\n",
              "      <td>-0.192215</td>\n",
              "      <td>0.137727</td>\n",
              "      <td>0.12689</td>\n",
              "      <td>-0.070395</td>\n",
              "      <td>0.261542</td>\n",
              "      <td>0.127427</td>\n",
              "      <td>-0.361265</td>\n",
              "      <td>0.073588</td>\n",
              "      <td>-0.058699</td>\n",
              "      <td>-0.056525</td>\n",
              "      <td>-0.167099</td>\n",
              "      <td>-0.375458</td>\n",
              "      <td>-0.059049</td>\n",
              "      <td>0.087339</td>\n",
              "      <td>0.104522</td>\n",
              "      <td>0.214481</td>\n",
              "      <td>-0.079478</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 201 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   date_int        0         1        2         3  ...  195  196  197  198  199\n",
              "0    201610  0.21916 -0.071963  0.17161  0.059836  ...  NaN  NaN  NaN  NaN  NaN\n",
              "\n",
              "[1 rows x 201 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7GG5K-q6T0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range( vector_dim ):\n",
        "   X_COV[str(vector_dim + i)] = X_prep.topic_1.apply( lambda x : select(x, i ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbanTosZ55UU",
        "colab_type": "code",
        "outputId": "bd105b63-3beb-4028-cfd1-158e6edffeef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "X_COV.head(1)"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date_int</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>160</th>\n",
              "      <th>161</th>\n",
              "      <th>162</th>\n",
              "      <th>163</th>\n",
              "      <th>164</th>\n",
              "      <th>165</th>\n",
              "      <th>166</th>\n",
              "      <th>167</th>\n",
              "      <th>168</th>\n",
              "      <th>169</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "      <th>180</th>\n",
              "      <th>181</th>\n",
              "      <th>182</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "      <th>188</th>\n",
              "      <th>189</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>193</th>\n",
              "      <th>194</th>\n",
              "      <th>195</th>\n",
              "      <th>196</th>\n",
              "      <th>197</th>\n",
              "      <th>198</th>\n",
              "      <th>199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>201610</td>\n",
              "      <td>0.21916</td>\n",
              "      <td>-0.071963</td>\n",
              "      <td>0.17161</td>\n",
              "      <td>0.059836</td>\n",
              "      <td>0.112974</td>\n",
              "      <td>0.054606</td>\n",
              "      <td>-0.121356</td>\n",
              "      <td>-0.037751</td>\n",
              "      <td>0.231681</td>\n",
              "      <td>0.143301</td>\n",
              "      <td>-0.083935</td>\n",
              "      <td>-0.000597</td>\n",
              "      <td>-0.102584</td>\n",
              "      <td>-0.223626</td>\n",
              "      <td>0.244886</td>\n",
              "      <td>0.015411</td>\n",
              "      <td>0.009623</td>\n",
              "      <td>0.088618</td>\n",
              "      <td>-0.023797</td>\n",
              "      <td>0.159932</td>\n",
              "      <td>-0.115685</td>\n",
              "      <td>0.073454</td>\n",
              "      <td>-0.192215</td>\n",
              "      <td>0.137727</td>\n",
              "      <td>0.12689</td>\n",
              "      <td>-0.070395</td>\n",
              "      <td>0.261542</td>\n",
              "      <td>0.127427</td>\n",
              "      <td>-0.361265</td>\n",
              "      <td>0.073588</td>\n",
              "      <td>-0.058699</td>\n",
              "      <td>-0.056525</td>\n",
              "      <td>-0.167099</td>\n",
              "      <td>-0.375458</td>\n",
              "      <td>-0.059049</td>\n",
              "      <td>0.087339</td>\n",
              "      <td>0.104522</td>\n",
              "      <td>0.214481</td>\n",
              "      <td>-0.079478</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.312944</td>\n",
              "      <td>0.471409</td>\n",
              "      <td>0.234812</td>\n",
              "      <td>0.264772</td>\n",
              "      <td>0.124698</td>\n",
              "      <td>0.37927</td>\n",
              "      <td>0.321631</td>\n",
              "      <td>0.29894</td>\n",
              "      <td>-0.269871</td>\n",
              "      <td>0.008393</td>\n",
              "      <td>-0.39878</td>\n",
              "      <td>0.250852</td>\n",
              "      <td>0.000388</td>\n",
              "      <td>0.606187</td>\n",
              "      <td>0.420323</td>\n",
              "      <td>0.075441</td>\n",
              "      <td>0.047697</td>\n",
              "      <td>-0.030579</td>\n",
              "      <td>0.072421</td>\n",
              "      <td>0.126686</td>\n",
              "      <td>-0.519172</td>\n",
              "      <td>-0.277032</td>\n",
              "      <td>-0.596734</td>\n",
              "      <td>-0.195425</td>\n",
              "      <td>-0.447811</td>\n",
              "      <td>-0.490741</td>\n",
              "      <td>-0.26947</td>\n",
              "      <td>0.212923</td>\n",
              "      <td>0.00727</td>\n",
              "      <td>0.097705</td>\n",
              "      <td>0.315443</td>\n",
              "      <td>0.352975</td>\n",
              "      <td>-0.065328</td>\n",
              "      <td>-0.376164</td>\n",
              "      <td>0.536453</td>\n",
              "      <td>-0.511859</td>\n",
              "      <td>0.297159</td>\n",
              "      <td>-0.114667</td>\n",
              "      <td>0.341746</td>\n",
              "      <td>-0.229836</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 201 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   date_int        0         1        2  ...       196       197       198       199\n",
              "0    201610  0.21916 -0.071963  0.17161  ...  0.297159 -0.114667  0.341746 -0.229836\n",
              "\n",
              "[1 rows x 201 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VA9RRpayfFGM",
        "colab_type": "text"
      },
      "source": [
        "The following code creates training and test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_ZO5jWRoFDK",
        "colab_type": "code",
        "outputId": "8d17db5c-321c-45c6-ecbd-69feff265f74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Y_COV = data_kaggle[ 'coverage' ]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_COV, Y_COV, test_size=0.33, random_state=42)\n",
        "print(\"train:\" , X_train.shape)\n",
        "print(\"test:\" , X_test.shape)"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train: (670, 201)\n",
            "test: (330, 201)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A767PTCrrp51",
        "colab_type": "code",
        "outputId": "8c4380c9-15fb-4dba-e53c-14f4a10d1bc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "X_COV.head(3)"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date_int</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>160</th>\n",
              "      <th>161</th>\n",
              "      <th>162</th>\n",
              "      <th>163</th>\n",
              "      <th>164</th>\n",
              "      <th>165</th>\n",
              "      <th>166</th>\n",
              "      <th>167</th>\n",
              "      <th>168</th>\n",
              "      <th>169</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "      <th>180</th>\n",
              "      <th>181</th>\n",
              "      <th>182</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "      <th>188</th>\n",
              "      <th>189</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>193</th>\n",
              "      <th>194</th>\n",
              "      <th>195</th>\n",
              "      <th>196</th>\n",
              "      <th>197</th>\n",
              "      <th>198</th>\n",
              "      <th>199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>201610</td>\n",
              "      <td>0.219160</td>\n",
              "      <td>-0.071963</td>\n",
              "      <td>0.171610</td>\n",
              "      <td>0.059836</td>\n",
              "      <td>0.112974</td>\n",
              "      <td>0.054606</td>\n",
              "      <td>-0.121356</td>\n",
              "      <td>-0.037751</td>\n",
              "      <td>0.231681</td>\n",
              "      <td>0.143301</td>\n",
              "      <td>-0.083935</td>\n",
              "      <td>-0.000597</td>\n",
              "      <td>-0.102584</td>\n",
              "      <td>-0.223626</td>\n",
              "      <td>0.244886</td>\n",
              "      <td>0.015411</td>\n",
              "      <td>0.009623</td>\n",
              "      <td>0.088618</td>\n",
              "      <td>-0.023797</td>\n",
              "      <td>0.159932</td>\n",
              "      <td>-0.115685</td>\n",
              "      <td>0.073454</td>\n",
              "      <td>-0.192215</td>\n",
              "      <td>0.137727</td>\n",
              "      <td>0.126890</td>\n",
              "      <td>-0.070395</td>\n",
              "      <td>0.261542</td>\n",
              "      <td>0.127427</td>\n",
              "      <td>-0.361265</td>\n",
              "      <td>0.073588</td>\n",
              "      <td>-0.058699</td>\n",
              "      <td>-0.056525</td>\n",
              "      <td>-0.167099</td>\n",
              "      <td>-0.375458</td>\n",
              "      <td>-0.059049</td>\n",
              "      <td>0.087339</td>\n",
              "      <td>0.104522</td>\n",
              "      <td>0.214481</td>\n",
              "      <td>-0.079478</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.312944</td>\n",
              "      <td>0.471409</td>\n",
              "      <td>0.234812</td>\n",
              "      <td>0.264772</td>\n",
              "      <td>0.124698</td>\n",
              "      <td>0.379270</td>\n",
              "      <td>0.321631</td>\n",
              "      <td>0.298940</td>\n",
              "      <td>-0.269871</td>\n",
              "      <td>0.008393</td>\n",
              "      <td>-0.398780</td>\n",
              "      <td>0.250852</td>\n",
              "      <td>0.000388</td>\n",
              "      <td>0.606187</td>\n",
              "      <td>0.420323</td>\n",
              "      <td>0.075441</td>\n",
              "      <td>0.047697</td>\n",
              "      <td>-0.030579</td>\n",
              "      <td>0.072421</td>\n",
              "      <td>0.126686</td>\n",
              "      <td>-0.519172</td>\n",
              "      <td>-0.277032</td>\n",
              "      <td>-0.596734</td>\n",
              "      <td>-0.195425</td>\n",
              "      <td>-0.447811</td>\n",
              "      <td>-0.490741</td>\n",
              "      <td>-0.269470</td>\n",
              "      <td>0.212923</td>\n",
              "      <td>0.007270</td>\n",
              "      <td>0.097705</td>\n",
              "      <td>0.315443</td>\n",
              "      <td>0.352975</td>\n",
              "      <td>-0.065328</td>\n",
              "      <td>-0.376164</td>\n",
              "      <td>0.536453</td>\n",
              "      <td>-0.511859</td>\n",
              "      <td>0.297159</td>\n",
              "      <td>-0.114667</td>\n",
              "      <td>0.341746</td>\n",
              "      <td>-0.229836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>201610</td>\n",
              "      <td>0.254377</td>\n",
              "      <td>-0.085566</td>\n",
              "      <td>0.212194</td>\n",
              "      <td>0.083735</td>\n",
              "      <td>0.155886</td>\n",
              "      <td>0.059181</td>\n",
              "      <td>-0.143602</td>\n",
              "      <td>-0.056493</td>\n",
              "      <td>0.280577</td>\n",
              "      <td>0.180164</td>\n",
              "      <td>-0.107588</td>\n",
              "      <td>0.004556</td>\n",
              "      <td>-0.111696</td>\n",
              "      <td>-0.276204</td>\n",
              "      <td>0.281616</td>\n",
              "      <td>0.007656</td>\n",
              "      <td>0.007148</td>\n",
              "      <td>0.114011</td>\n",
              "      <td>-0.026908</td>\n",
              "      <td>0.190499</td>\n",
              "      <td>-0.158394</td>\n",
              "      <td>0.094110</td>\n",
              "      <td>-0.226749</td>\n",
              "      <td>0.156999</td>\n",
              "      <td>0.151708</td>\n",
              "      <td>-0.089810</td>\n",
              "      <td>0.323877</td>\n",
              "      <td>0.148745</td>\n",
              "      <td>-0.438090</td>\n",
              "      <td>0.098714</td>\n",
              "      <td>-0.070521</td>\n",
              "      <td>-0.063779</td>\n",
              "      <td>-0.191515</td>\n",
              "      <td>-0.454348</td>\n",
              "      <td>-0.084786</td>\n",
              "      <td>0.106679</td>\n",
              "      <td>0.128884</td>\n",
              "      <td>0.261943</td>\n",
              "      <td>-0.099988</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.243179</td>\n",
              "      <td>0.385696</td>\n",
              "      <td>0.209683</td>\n",
              "      <td>0.204074</td>\n",
              "      <td>0.086538</td>\n",
              "      <td>0.288448</td>\n",
              "      <td>0.268089</td>\n",
              "      <td>0.190552</td>\n",
              "      <td>-0.202683</td>\n",
              "      <td>-0.003857</td>\n",
              "      <td>-0.354625</td>\n",
              "      <td>0.244868</td>\n",
              "      <td>-0.070185</td>\n",
              "      <td>0.437139</td>\n",
              "      <td>0.356539</td>\n",
              "      <td>-0.013492</td>\n",
              "      <td>-0.028354</td>\n",
              "      <td>-0.074271</td>\n",
              "      <td>0.063069</td>\n",
              "      <td>0.133044</td>\n",
              "      <td>-0.389222</td>\n",
              "      <td>-0.132875</td>\n",
              "      <td>-0.423707</td>\n",
              "      <td>-0.135533</td>\n",
              "      <td>-0.458793</td>\n",
              "      <td>-0.432255</td>\n",
              "      <td>-0.216967</td>\n",
              "      <td>0.235955</td>\n",
              "      <td>0.050896</td>\n",
              "      <td>0.066565</td>\n",
              "      <td>0.186090</td>\n",
              "      <td>0.323265</td>\n",
              "      <td>-0.061149</td>\n",
              "      <td>-0.336219</td>\n",
              "      <td>0.470441</td>\n",
              "      <td>-0.471960</td>\n",
              "      <td>0.246104</td>\n",
              "      <td>-0.088893</td>\n",
              "      <td>0.305072</td>\n",
              "      <td>-0.097314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>201610</td>\n",
              "      <td>0.360090</td>\n",
              "      <td>-0.136373</td>\n",
              "      <td>0.289292</td>\n",
              "      <td>0.127049</td>\n",
              "      <td>0.225737</td>\n",
              "      <td>0.093560</td>\n",
              "      <td>-0.174556</td>\n",
              "      <td>-0.118257</td>\n",
              "      <td>0.425192</td>\n",
              "      <td>0.265143</td>\n",
              "      <td>-0.135146</td>\n",
              "      <td>0.019592</td>\n",
              "      <td>-0.157894</td>\n",
              "      <td>-0.380727</td>\n",
              "      <td>0.392563</td>\n",
              "      <td>-0.027757</td>\n",
              "      <td>-0.010990</td>\n",
              "      <td>0.165676</td>\n",
              "      <td>-0.067164</td>\n",
              "      <td>0.276725</td>\n",
              "      <td>-0.288686</td>\n",
              "      <td>0.100975</td>\n",
              "      <td>-0.393011</td>\n",
              "      <td>0.247915</td>\n",
              "      <td>0.183379</td>\n",
              "      <td>-0.198192</td>\n",
              "      <td>0.492081</td>\n",
              "      <td>0.175080</td>\n",
              "      <td>-0.664474</td>\n",
              "      <td>0.168538</td>\n",
              "      <td>-0.078785</td>\n",
              "      <td>-0.064312</td>\n",
              "      <td>-0.233542</td>\n",
              "      <td>-0.642523</td>\n",
              "      <td>-0.192583</td>\n",
              "      <td>0.135402</td>\n",
              "      <td>0.182446</td>\n",
              "      <td>0.383757</td>\n",
              "      <td>-0.151305</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.175468</td>\n",
              "      <td>0.274961</td>\n",
              "      <td>0.153761</td>\n",
              "      <td>0.149677</td>\n",
              "      <td>0.052596</td>\n",
              "      <td>0.213806</td>\n",
              "      <td>0.195321</td>\n",
              "      <td>0.136030</td>\n",
              "      <td>-0.140689</td>\n",
              "      <td>-0.003512</td>\n",
              "      <td>-0.253983</td>\n",
              "      <td>0.183008</td>\n",
              "      <td>-0.058616</td>\n",
              "      <td>0.311010</td>\n",
              "      <td>0.241580</td>\n",
              "      <td>-0.020845</td>\n",
              "      <td>-0.027297</td>\n",
              "      <td>-0.044356</td>\n",
              "      <td>0.057756</td>\n",
              "      <td>0.100599</td>\n",
              "      <td>-0.285204</td>\n",
              "      <td>-0.098006</td>\n",
              "      <td>-0.279161</td>\n",
              "      <td>-0.090023</td>\n",
              "      <td>-0.327278</td>\n",
              "      <td>-0.301183</td>\n",
              "      <td>-0.159784</td>\n",
              "      <td>0.161246</td>\n",
              "      <td>0.034036</td>\n",
              "      <td>0.048734</td>\n",
              "      <td>0.119194</td>\n",
              "      <td>0.227648</td>\n",
              "      <td>-0.052141</td>\n",
              "      <td>-0.244023</td>\n",
              "      <td>0.340995</td>\n",
              "      <td>-0.335974</td>\n",
              "      <td>0.178393</td>\n",
              "      <td>-0.061029</td>\n",
              "      <td>0.209100</td>\n",
              "      <td>-0.062760</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 201 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   date_int         0         1  ...       197       198       199\n",
              "0    201610  0.219160 -0.071963  ... -0.114667  0.341746 -0.229836\n",
              "1    201610  0.254377 -0.085566  ... -0.088893  0.305072 -0.097314\n",
              "2    201610  0.360090 -0.136373  ... -0.061029  0.209100 -0.062760\n",
              "\n",
              "[3 rows x 201 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeWd0pHVqn6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f_cov = RandomForestClassifier(n_estimators=10)\n",
        "f_cov.fit(X_train, y_train)\n",
        "y_pred = f_cov.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awhW0Wfr6tao",
        "colab_type": "text"
      },
      "source": [
        "Predicting the accuracy of the coverage,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S28IoxY6wVL",
        "colab_type": "code",
        "outputId": "56b13861-87f7-444d-d6d1-a01cc20103e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "'Accuracy', metrics.accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Accuracy', 0.9151515151515152)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0Lt5tBu1bQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "num_folds = 10\n",
        "seed = 7\n",
        "scoring = 'accuracy'\n",
        "\n",
        "models = []\n",
        "models.append(('LR' , LogisticRegression()))\n",
        "models.append(('LDA' , LinearDiscriminantAnalysis()))\n",
        "#models.append(('KNN' , KNeighborsClassifier()))\n",
        "#models.append(('CART' , DecisionTreeClassifier()))\n",
        "#models.append(('NB' , GaussianNB()))\n",
        "#models.append(('SVM' , SVC()))\n",
        "#models.append(('MNB', MultinomialNB()))\n",
        "models.append(('RF' , RandomForestClassifier(n_estimators=50)))\n",
        "#models.append(('XGBoost', XGBClassifier()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_WWzOq31y-9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "9c28936b-fd65-4ef1-d83c-dff9f049445c"
      },
      "source": [
        "results = []\n",
        "names = []\n",
        "\n",
        "'''\n",
        "for name, model in models:\n",
        "  kfold = KFold(n_splits=num_folds, random_state=42)\n",
        "  cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
        "  results.append(cv_results)\n",
        "  names.append(name)\n",
        "  msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "  print(msg) '''\n",
        "\n",
        "for name, model in models:\n",
        "    clf = model\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    accu_score = accuracy_score(y_test, y_pred)\n",
        "    print(name + \": \" + str(accu_score))"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LR: 0.9121212121212121\n",
            "LDA: 0.8121212121212121\n",
            "RF: 0.9303030303030303\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHC2IGew6_Qg",
        "colab_type": "text"
      },
      "source": [
        "The accuracy based on the unseen test data is 90%~95%. This means that using the word2vec-based model one can build a reliable coverage score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6qus8Ai7dux",
        "colab_type": "code",
        "outputId": "524e3bc4-4ef3-4b04-8b77-14cef39145dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "importantCols = pd.Series(f_cov.feature_importances_,index=list(X_COV)).sort_values(ascending=False)\n",
        "sns.barplot(y=importantCols[:20], x=importantCols.index[:20])\n",
        "\n",
        "plt.ylabel('Importance Score')\n",
        "plt.xlabel('Columns')\n",
        "plt.title(\"Importance Sorted\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiWlQq2M-tfz",
        "colab_type": "text"
      },
      "source": [
        "### 7.15 Interpretation\n",
        "\n",
        "As shown above \"`date_int`\"  is one of the most important feature in determining whether or not the news has high news coverage. This is expected since the date the news has been posted definitely impacts on whether the news has sufficient coverage from peer articles. Some of the numeric (word2vec) columns  have significant impact on the prediction of the coverage score. But, since these factors are latent, they do not correspond to specific words in the vocabulary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiIceCrcYqx9",
        "colab_type": "text"
      },
      "source": [
        "### 7.16 Other Methods Tried\n",
        "Also tried using TFIDF as well as shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_b0jANCS4Jx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "ktdv = TfidfVectorizer()\n",
        "  \n",
        "data_kaggle['text_distilled_joined'] = data_kaggle[ 'text_distilled' ].apply( lambda x :  ' '.join( x ) )\n",
        "ktdv.fit( data_kaggle[ 'text_distilled_joined' ])\n",
        "dim_row = len(ktdv.transform([data_kaggle[ 'text_distilled_joined' ][0]]).toarray())\n",
        "dim_col = len(ktdv.transform([data_kaggle[ 'text_distilled_joined' ][0]]).toarray()[0])\n",
        "# Eventually dropped"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7lp6PDLbb7c",
        "colab_type": "text"
      },
      "source": [
        "### 7.17 Extension - Increase  the window to 2 Months\n",
        "\n",
        "Now that we have coverage of 5 and above for 6/100 articles. We can try and see what values we see if the coverage is increased from 30 days to 60 days"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKe0HrIYcHp_",
        "colab_type": "code",
        "outputId": "59635077-452f-4db7-ca20-5ee8383c4aac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "def coverage60( article ):\n",
        "   fromdate, todate = window( article[ 'date' ], 60 )\n",
        "   selected_coverage = all_kaggle[(all_kaggle['date'] > fromdate) & (all_kaggle['date'] < todate)]\n",
        "   selected_coverage['covered'] = selected_coverage.apply( lambda r: r[ 'topics' ][0] in article.topics and\n",
        "                                                       r[ 'topics' ][1] in article.topics, axis=1 )\n",
        "   return len(selected_coverage[selected_coverage['covered'] == True])\n",
        "\n",
        "data_kaggle[ 'coverage60' ] = data_kaggle.apply( coverage60, axis=1 )"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw8RejabdY8t",
        "colab_type": "code",
        "outputId": "35e798bd-acc9-4019-e8cd-4719b60ea824",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        }
      },
      "source": [
        "data_kaggle.sort_values(by=['coverage'], ascending=False ).head(5)"
      ],
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uuid</th>\n",
              "      <th>ord_in_thread</th>\n",
              "      <th>author</th>\n",
              "      <th>published</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>language</th>\n",
              "      <th>crawled</th>\n",
              "      <th>site_url</th>\n",
              "      <th>country</th>\n",
              "      <th>domain_rank</th>\n",
              "      <th>thread_title</th>\n",
              "      <th>spam_score</th>\n",
              "      <th>main_img_url</th>\n",
              "      <th>replies_count</th>\n",
              "      <th>participants_count</th>\n",
              "      <th>likes</th>\n",
              "      <th>comments</th>\n",
              "      <th>shares</th>\n",
              "      <th>type</th>\n",
              "      <th>text_distilled</th>\n",
              "      <th>text_distilled_lemma</th>\n",
              "      <th>topics</th>\n",
              "      <th>date</th>\n",
              "      <th>coverage</th>\n",
              "      <th>topic_0</th>\n",
              "      <th>topic_1</th>\n",
              "      <th>text_distilled_joined</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>date_int</th>\n",
              "      <th>coverage60</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>a36405a8d7d32c2192b9a9b482dcf0ebc83c62eb</td>\n",
              "      <td>0</td>\n",
              "      <td>Mike Rivero</td>\n",
              "      <td>2016-11-23T00:49:00.000+02:00</td>\n",
              "      <td>FLASHBACK - Hillary Clinton’s ‘KKK’ Smear Agai...</td>\n",
              "      <td>November 21, 2016 By 21wire Leave a Comment \\n...</td>\n",
              "      <td>english</td>\n",
              "      <td>2016-11-23T01:36:58.899+02:00</td>\n",
              "      <td>21stcenturywire.com</td>\n",
              "      <td>US</td>\n",
              "      <td>NaN</td>\n",
              "      <td>FLASHBACK - Hillary Clinton’s ‘KKK’ Smear Agai...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>http://i2.wp.com/21stcenturywire.com/wp-conten...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>conspiracy</td>\n",
              "      <td>[flashback, hillary, clinton, kkk, smear, trum...</td>\n",
              "      <td>[flashback, hillary, clinton, s, kkk, smear, a...</td>\n",
              "      <td>[mr , trump]</td>\n",
              "      <td>2016-11-23</td>\n",
              "      <td>41</td>\n",
              "      <td>[0.5996305346488953, -0.2831524610519409, 0.41...</td>\n",
              "      <td>[0.48507755994796753, -0.6275070905685425, -0....</td>\n",
              "      <td>flashback hillary clinton kkk smear trump demo...</td>\n",
              "      <td>{'neg': 0.141, 'neu': 0.737, 'pos': 0.122, 'co...</td>\n",
              "      <td>201611</td>\n",
              "      <td>118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>c1a86b752a21196a06591d5a785fa29b14fab245</td>\n",
              "      <td>0</td>\n",
              "      <td>EdJenner</td>\n",
              "      <td>2016-11-22T08:17:53.961+02:00</td>\n",
              "      <td>DONALD TRUMP Calls Meeting With Press…Dresses ...</td>\n",
              "      <td>Go to Article \\nThey had to know they had it c...</td>\n",
              "      <td>english</td>\n",
              "      <td>2016-11-22T08:17:53.961+02:00</td>\n",
              "      <td>100percentfedup.com</td>\n",
              "      <td>US</td>\n",
              "      <td>25689.0</td>\n",
              "      <td>DONALD TRUMP Calls Meeting With Press…Dresses ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>http://conservativeangle.com/wp-content/upload...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>bias</td>\n",
              "      <td>[donald, trump, calls, meeting, press, dresses...</td>\n",
              "      <td>[donald, trump, call, meeting, with, press, dr...</td>\n",
              "      <td>[trump , said]</td>\n",
              "      <td>2016-11-22</td>\n",
              "      <td>23</td>\n",
              "      <td>[0.48507755994796753, -0.6275070905685425, -0....</td>\n",
              "      <td>[0.492237389087677, -0.26270371675491333, 0.36...</td>\n",
              "      <td>donald trump calls meeting press dresses real ...</td>\n",
              "      <td>{'neg': 0.217, 'neu': 0.719, 'pos': 0.064, 'co...</td>\n",
              "      <td>201611</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>959</th>\n",
              "      <td>62a33ca2aa94dede5212714fd0d31ffb3ee089e1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2016-10-27T21:14:42.443+03:00</td>\n",
              "      <td>Trump warns of World War III if Clinton is ele...</td>\n",
              "      <td>Email Donald Trump warned in an interview Tues...</td>\n",
              "      <td>english</td>\n",
              "      <td>2016-10-27T21:14:42.443+03:00</td>\n",
              "      <td>awdnews.com</td>\n",
              "      <td>DE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Trump warns of World War III if Clinton is ele...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>http://awdnews.com/images/14775862276361308531...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>conspiracy</td>\n",
              "      <td>[trump, warns, world, war, iii, clinton, elect...</td>\n",
              "      <td>[trump, warns, of, world, war, iii, if, clinto...</td>\n",
              "      <td>[trump , clinton]</td>\n",
              "      <td>2016-10-27</td>\n",
              "      <td>23</td>\n",
              "      <td>[0.48507755994796753, -0.6275070905685425, -0....</td>\n",
              "      <td>[0.2722969651222229, -0.426133930683136, 0.207...</td>\n",
              "      <td>trump warns world war iii clinton elected emai...</td>\n",
              "      <td>{'neg': 0.236, 'neu': 0.639, 'pos': 0.126, 'co...</td>\n",
              "      <td>201610</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>980</th>\n",
              "      <td>29aa6e6c0aa6e47a2ee80e18b8ddc031657425b0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2016-10-28T18:34:48.985+03:00</td>\n",
              "      <td>FEAR OF TRUMP: BUSH, OBAMA, CLINTON ALL BUYING...</td>\n",
              "      <td>Email \\n\\nIt appears Bill and Hillary Clinton ...</td>\n",
              "      <td>english</td>\n",
              "      <td>2016-10-28T18:34:48.985+03:00</td>\n",
              "      <td>awdnews.com</td>\n",
              "      <td>DE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>FEAR OF TRUMP: BUSH, OBAMA, CLINTON ALL BUYING...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>http://awdnews.com/images/14776680451.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>conspiracy</td>\n",
              "      <td>[fear, trump, bush, obama, clinton, buying, pr...</td>\n",
              "      <td>[fear, of, trump, bush, obama, clinton, all, b...</td>\n",
              "      <td>[trump , clinton]</td>\n",
              "      <td>2016-10-28</td>\n",
              "      <td>21</td>\n",
              "      <td>[0.48507755994796753, -0.6275070905685425, -0....</td>\n",
              "      <td>[0.2722969651222229, -0.426133930683136, 0.207...</td>\n",
              "      <td>fear trump bush obama clinton buying property ...</td>\n",
              "      <td>{'neg': 0.107, 'neu': 0.745, 'pos': 0.148, 'co...</td>\n",
              "      <td>201610</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>988</th>\n",
              "      <td>b2e81b8debd3ca29f942d34b781126c07e427194</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2016-10-28T18:40:18.626+03:00</td>\n",
              "      <td>FEAR OF TRUMP: BUSH, OBAMA, CLINTON ALL BUYING...</td>\n",
              "      <td>Email \\n\\nIt appears Bill and Hillary Clinton ...</td>\n",
              "      <td>english</td>\n",
              "      <td>2016-10-28T18:40:18.626+03:00</td>\n",
              "      <td>awdnews.com</td>\n",
              "      <td>DE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>FEAR OF TRUMP: BUSH, OBAMA, CLINTON ALL BUYING...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>http://awdnews.com/images/14776680451.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>conspiracy</td>\n",
              "      <td>[fear, trump, bush, obama, clinton, buying, pr...</td>\n",
              "      <td>[fear, of, trump, bush, obama, clinton, all, b...</td>\n",
              "      <td>[trump , clinton]</td>\n",
              "      <td>2016-10-28</td>\n",
              "      <td>21</td>\n",
              "      <td>[0.48507755994796753, -0.6275070905685425, -0....</td>\n",
              "      <td>[0.2722969651222229, -0.426133930683136, 0.207...</td>\n",
              "      <td>fear trump bush obama clinton buying property ...</td>\n",
              "      <td>{'neg': 0.107, 'neu': 0.745, 'pos': 0.148, 'co...</td>\n",
              "      <td>201610</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         uuid  ...  coverage60\n",
              "53   a36405a8d7d32c2192b9a9b482dcf0ebc83c62eb  ...         118\n",
              "26   c1a86b752a21196a06591d5a785fa29b14fab245  ...          66\n",
              "959  62a33ca2aa94dede5212714fd0d31ffb3ee089e1  ...         100\n",
              "980  29aa6e6c0aa6e47a2ee80e18b8ddc031657425b0  ...          98\n",
              "988  b2e81b8debd3ca29f942d34b781126c07e427194  ...          98\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntHZZBZre56u",
        "colab_type": "text"
      },
      "source": [
        "Counting number of articles with coverage scores above 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PcffI6Oe9-9",
        "colab_type": "code",
        "outputId": "fd39cff0-2e58-4aa6-e126-cbb02b5d5bb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(data_kaggle[data_kaggle['coverage60']>1])"
      ],
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 257
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhnJaXY8cVtD",
        "colab_type": "text"
      },
      "source": [
        "### 7.18 Testing on Non-Fake News\n",
        "\n",
        "The coverage scores (with window = 60 days) are compared between fake news dataset and \"All news\" non-fake news dataset. Since window of 60 days are chosen for fake news dataset, the same window is chosen for non-fake datasets for consistency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbcKaZ3MdNBz",
        "colab_type": "code",
        "outputId": "d52640fc-4e56-414e-b48b-c16496de7976",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "non_fake_data = all_kaggle[:100]\n",
        "\n",
        "non_fake_data[ 'coverage60' ] = non_fake_data.apply( coverage60, axis=1 )"
      ],
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjnAL_cxebSx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "outputId": "5528a42d-15fc-4f8c-b1c4-324ac40751bd"
      },
      "source": [
        "non_fake_data.sort_values(by=['coverage60'], ascending=False ).head(5)"
      ],
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>publication</th>\n",
              "      <th>author</th>\n",
              "      <th>date</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>url</th>\n",
              "      <th>content</th>\n",
              "      <th>text_distilled</th>\n",
              "      <th>topics</th>\n",
              "      <th>coverage60</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>93</td>\n",
              "      <td>17392</td>\n",
              "      <td>Trump Takes on Democrats and Health Law in New...</td>\n",
              "      <td>New York Times</td>\n",
              "      <td>Julie Hirschfeld Davis</td>\n",
              "      <td>2017-01-06</td>\n",
              "      <td>2017.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>WASHINGTON  —     Donald J. Trump lashed out a...</td>\n",
              "      <td>[trump, take, democrat, health, law, new, twit...</td>\n",
              "      <td>[mr , trump]</td>\n",
              "      <td>157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>43</td>\n",
              "      <td>17334</td>\n",
              "      <td>Trump Appears to Side With Assange Over Intell...</td>\n",
              "      <td>New York Times</td>\n",
              "      <td>Scott Shane, Maggie Haberman and Julie Hirschf...</td>\n",
              "      <td>2017-01-05</td>\n",
              "      <td>2017.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>■   Donald J. Trump appears to side with the W...</td>\n",
              "      <td>[trump, appears, side, assange, intelligence, ...</td>\n",
              "      <td>[mr , trump]</td>\n",
              "      <td>157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>17295</td>\n",
              "      <td>Mar-a-Lago, the Future Winter White House and ...</td>\n",
              "      <td>New York Times</td>\n",
              "      <td>Maggie Haberman</td>\n",
              "      <td>2017-01-02</td>\n",
              "      <td>2017.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>WEST PALM BEACH, Fla.  —   When   Donald J. Tr...</td>\n",
              "      <td>[mar, lago, future, winter, white, house, home...</td>\n",
              "      <td>[mr , trump]</td>\n",
              "      <td>154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>77</td>\n",
              "      <td>17373</td>\n",
              "      <td>Enough With the Tweets, China’s State Media Te...</td>\n",
              "      <td>New York Times</td>\n",
              "      <td>Chris Buckley</td>\n",
              "      <td>2017-01-05</td>\n",
              "      <td>2017.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>BEIJING  —   China’s leaders thought they had ...</td>\n",
              "      <td>[enough, tweet, china, state, medium, tell, tr...</td>\n",
              "      <td>[trump , mr]</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>17293</td>\n",
              "      <td>Weak Federal Powers Could Limit Trump’s Climat...</td>\n",
              "      <td>New York Times</td>\n",
              "      <td>Justin Gillis</td>\n",
              "      <td>2017-01-03</td>\n",
              "      <td>2017.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>With Donald J. Trump about to take control of ...</td>\n",
              "      <td>[weak, federal, power, could, limit, trump, cl...</td>\n",
              "      <td>[trump , mr]</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Unnamed: 0     id  ...        topics coverage60\n",
              "93          93  17392  ...  [mr , trump]        157\n",
              "43          43  17334  ...  [mr , trump]        157\n",
              "12          12  17295  ...  [mr , trump]        154\n",
              "77          77  17373  ...  [trump , mr]         72\n",
              "10          10  17293  ...  [trump , mr]         72\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mgwc_azbfHdK",
        "colab_type": "text"
      },
      "source": [
        "Counting the number of articles with coverage score greater than 1,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ1dxOHVfKOh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c97dc441-c32c-487b-ce41-f2dcf04fbc12"
      },
      "source": [
        "len(non_fake_data[non_fake_data['coverage60']>1])"
      ],
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 261
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CadFX0H6T3Qg",
        "colab_type": "text"
      },
      "source": [
        "### 7.19 Comparisons between Fake and Non-Fake News Datasets\n",
        "\n",
        "Based on sample of 100 articles from pool of fake and non-fake news sources, the coverage score for non-fake news articles are significantly higher than the fake news articles. In particular, around 30 out of 100 of non-fake news articles had coverage score greater than one. On the other hand, only 14 out of 100 of fake news articles had coverge score greater than one. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2qLJGG11B6n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a971c33f-9178-4ed8-8c75-f43034bda49e"
      },
      "source": [
        "# For caculating approximate time to process notebook (IGNORE)\n",
        "import datetime\n",
        "datetime.datetime.now()"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datetime.datetime(2020, 4, 26, 10, 8, 23, 418443)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkzIohC5pBQS",
        "colab_type": "text"
      },
      "source": [
        "## 9 Preparing for the Polynomial (News Coverage Score)\n",
        "\n",
        "To prepare for polynomial equation, we should apply the rank to the combined dataset of fake and non-fake news, prepared by Gene. Here are several reasons news coverage score has been chosen:\n",
        "\n",
        "- More accurate model\n",
        "- Clear difference between all news data set and fakenews dataset\n",
        "- Interest of time and resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uf6lwvd-YZ3t",
        "colab_type": "text"
      },
      "source": [
        "#### 9.1 Cleaning Up Exiting Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AmiK2Atuyyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clean up some existing data\n",
        "\n",
        "all_kaggle = all_kaggle.iloc[0:0]\n",
        "data_kaggle = data_kaggle.iloc[0:0] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2Ydtpy1YiyL",
        "colab_type": "text"
      },
      "source": [
        "### 9.2 Uniform Data Preparation (By Gene)\n",
        "\n",
        "We need to apply our trained model on Gene's prepared data. No training is required. We just need to apply our model to this dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgkthGJX5AKG",
        "colab_type": "code",
        "outputId": "3e83351c-f9c3-469b-e19b-c2c923412b39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "!pip install gensim"
      ],
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.3)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.12.43)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.21.0)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.5)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.43 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.15.43)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.3.3)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->smart-open>=1.2.1->gensim) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPc-q4aGpgtl",
        "colab_type": "code",
        "outputId": "63f3f3e7-9c67-4b6a-a776-4f502cf986e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "##### PREPARED BY GENE #####\n",
        "# dependencies\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import numpy as np\n",
        "import io\n",
        "import requests\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "# from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.feature_selection import chi2\n",
        "from string import punctuation\n",
        "from nltk import PorterStemmer\n",
        "import copy \n",
        "import re, math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk import WordNetLemmatizer\n",
        "from nltk import bigrams\n",
        "from nltk.util import ngrams\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from gensim.models.ldamodel import LdaModel\n",
        "from gensim.corpora import Dictionary\n",
        "import pickle\n",
        "from collections import Counter\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 265
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHe-bOHApmVA",
        "colab_type": "code",
        "outputId": "fe8b20fc-1356-4d8e-9bcf-d063b485af8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "##### PREPARED BY GENE #####\n",
        "def get_parsed_data2(url):\n",
        "    return pd.read_csv(io.StringIO(requests.get(url, verify=False).content.decode('utf-8')), sep=',', header='infer')\n",
        "\n",
        "# download and parse the dataset...\n",
        "data_kg_fake_news = get_parsed_data2('https://github.com/synle/machine-learning-sample-dataset/raw/master/liar_dataset/kaggle/kaggle-fake.csv')"
      ],
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3AuNeD_9u67",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "49ee0b18-cf11-45ef-a47d-37536d932d46"
      },
      "source": [
        "# All News Kaggle\n",
        "\n",
        "def get_parsed_data2(url):\n",
        "    return pd.read_csv(io.StringIO(requests.get(url, verify=False).content.decode('utf-8')), sep=',', header='infer')\n",
        "\n",
        "# download and parse the dataset...\n",
        "data_kg_nonfake_news = get_parsed_data2('https://media.githubusercontent.com/media/hyunwookshin/all_news_dataset_kaggle/master/articles1.csv')"
      ],
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4XaxlhWpwy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### PREPARED BY GENE (MODIFIED) #####\n",
        "def tokenize2(text):\n",
        "    cachedStopWords = set(stopwords.words('english') + list(punctuation))\n",
        "    min_length = 3\n",
        "    # tokenize\n",
        "    # convert to lower case\n",
        "    words = map(lambda word: word.lower(), word_tokenize(text))\n",
        "    # remove stop words\n",
        "    words = [word for word in words if word not in cachedStopWords]\n",
        "    # steming\n",
        "    #tokens = list(map(lambda token: PorterStemmer().stem(token), words))\n",
        "    # lemmatize\n",
        "    lemmas = [WordNetLemmatizer().lemmatize(word) for word in words]\n",
        "    # only focus on alphabetic words\n",
        "    p = re.compile('[a-zA-Z]+')\n",
        "    \n",
        "    filtered_lemmas = list(filter(lambda lemma: p.match(lemma) and len(lemma) >= min_length, lemmas))\n",
        "    return filtered_lemmas\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5w6iiEZ0JTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### PREPARED BY GENE (MODIFIED)\n",
        "data_kg_nonfake_news.rename(columns={\"content\": \"text\"}, inplace=True)\n",
        "data_kg_nonfake_news['type'] = 0\n",
        "data_kg_fake_news.loc[data_kg_fake_news['type']!='bs', 'type'] = 0\n",
        "data_kg_fake_news.loc[data_kg_fake_news['type']=='bs', 'type'] = 1\n",
        "\n",
        "\n",
        "### From Earlier Part of the assignment\n",
        "def setDate( published ):\n",
        "   return published.split( \"T\" )[0]\n",
        "  \n",
        "data_kg_fake_news[ 'date' ] = data_kg_fake_news.published.apply( setDate )\n",
        "\n",
        "all_data = pd.concat([data_kg_fake_news[['date', 'title','text','type']], data_kg_nonfake_news[['date', 'title','text','type']]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aceO8aMm5-bM",
        "colab_type": "code",
        "outputId": "eb9ef6cb-7872-4dee-f249-9ffd8dda504e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "all_data.type.value_counts()"
      ],
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    51507\n",
              "1    11492\n",
              "Name: type, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 270
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg9ucgHo6lUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data_to_export = all_data[[\"title\"]]\n",
        "all_data_to_export.to_csv('all_data_mini.csv', 'w' )\n",
        "from google.colab import files\n",
        "\n",
        "files.download('all_data_mini.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGwTsk1gp62l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### PREPARED BY GENE #####\n",
        "all_data['text_clean']=all_data['text'].astype('U').apply(tokenize2)\n",
        "#all_data['title_clean']=all_data['title'].astype('U').apply(tokenize2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gToCjmRTrEDe",
        "colab_type": "text"
      },
      "source": [
        "Please refer to section 7.9 - 14 for explanations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npXQ9HDU3Nsl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "af9af970-dfa2-4dff-e939-81f3583ccc66"
      },
      "source": [
        "all_data.text_clean.head(2)"
      ],
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [print, pay, back, money, plus, interest, enti...\n",
              "1    [attorney, general, loretta, lynch, plead, fif...\n",
              "Name: text_clean, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 273
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53nejRhj6IbI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "10dcc5a1-559f-4796-9808-d04157e4a18a"
      },
      "source": [
        "all_data.type.value_counts()"
      ],
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    51507\n",
              "1    11492\n",
              "Name: type, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auh3CfmuZFsL",
        "colab_type": "text"
      },
      "source": [
        "### 9.3 Applying LDA (as done before)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUk43bSXqsZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#all_data['text_distilled'] = all_data[ 'text_clean' ].apply( lambda x : x.split())\n",
        "from gensim.models.ldamodel import LdaModel\n",
        "from gensim.corpora import Dictionary\n",
        "\n",
        "def topics(tokenized_words):\n",
        "    if len( tokenized_words ) == 0 :\n",
        "      return []\n",
        "    d = Dictionary([tokenized_words])\n",
        "    c = [d.doc2bow(tokenized_words)]\n",
        "    m = LdaModel(c, num_topics=1, id2word=d)\n",
        "    return list(m.print_topics(num_words=2))\n",
        "  \n",
        "all_data['topics'] = all_data['text_clean'].apply(topics)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAVl3EZk5wHR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "fc1a9b8c-4c78-4fe8-e1d5-0178bbc7f421"
      },
      "source": [
        "all_data['topics'].head(20)"
      ],
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         [(0, 0.036*\"government\" + 0.036*\"group\")]\n",
              "1            [(0, 0.033*\"lynch\" + 0.022*\"payment\")]\n",
              "2              [(0, 0.027*\"weiner\" + 0.018*\"form\")]\n",
              "3           [(0, 0.056*\"mueller\" + 0.056*\"speech\")]\n",
              "4           [(0, 0.024*\"insurance\" + 0.018*\"must\")]\n",
              "5             [(0, 0.035*\"clinton\" + 0.030*\"bill\")]\n",
              "6           [(0, 0.017*\"prince\" + 0.015*\"justice\")]\n",
              "7          [(0, 0.019*\"election\" + 0.017*\"ballot\")]\n",
              "8            [(0, 0.034*\"clinton\" + 0.029*\"email\")]\n",
              "9              [(0, 0.031*\"lee\" + 0.031*\"nothing\")]\n",
              "10                                               []\n",
              "11              [(0, 0.052*\"move\" + 0.042*\"would\")]\n",
              "12        [(0, 0.020*\"student\" + 0.015*\"michigan\")]\n",
              "13             [(0, 0.032*\"obama\" + 0.022*\"trump\")]\n",
              "14    [(0, 0.056*\"alliance\" + 0.056*\"association\")]\n",
              "15               [(0, 0.058*\"one\" + 0.058*\"trump\")]\n",
              "16    [(0, 0.056*\"alliance\" + 0.056*\"association\")]\n",
              "17          [(0, 0.021*\"trump\" + 0.010*\"election\")]\n",
              "18            [(0, 0.031*\"painting\" + 0.027*\"man\")]\n",
              "19           [(0, 0.029*\"vote\" + 0.021*\"absentee\")]\n",
              "Name: topics, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA6Uytjb5rIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def parseTopics(topics):\n",
        "   output = []\n",
        "   if len( topics ) >= 1 :\n",
        "      words = topics[0][1].split( '+' )\n",
        "   else:\n",
        "      return []\n",
        "   for word in words:\n",
        "       if '*' not in word:\n",
        "           print(word)\n",
        "           output.append( word )\n",
        "       else:\n",
        "           output.append( word.split('*')[1].replace( '\"', '' ) )\n",
        "   if len( output ) < 2:\n",
        "      output.append( output[0] )\n",
        "   if len( output ) != 2:\n",
        "      return output[:2]\n",
        "   if not isinstance( output[0], str ) or not isinstance( output[1], str ):\n",
        "      print( output )\n",
        "      assert isinstance( output[0], str )\n",
        "      assert isinstance( output[1], str )\n",
        "   return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIpZ2p7orDIc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "5c4d3341-dd7a-41db-bb2e-7a2110b7b161"
      },
      "source": [
        "all_data['topics'] = all_data['topics'].apply(parseTopics)"
      ],
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "force\"\n",
            "placement\"\n",
            "placement\"\n",
            "force\"\n",
            "1z\"\n",
            "1z\"\n",
            "1z\"\n",
            "1z\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDHoVJiOY9-_",
        "colab_type": "text"
      },
      "source": [
        "### 9.4 Encoding Topics using word2vec (Same Practice)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMHYRuc3rStb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "ee7ec3f3-351e-4f1b-ab93-4527a89571e3"
      },
      "source": [
        "m = Word2Vec( all_data[ 'text_clean' ] )\n",
        "vector_dim = len(m[list(m.wv.vocab)[0]])\n",
        "\n",
        "def encodeFirstColumn( topics ):\n",
        "   if len(topics) == 0:\n",
        "      return np.zeros( len(m[list(m.wv.vocab)[0]]) ).tolist()\n",
        "   topic = topics[0].strip()\n",
        "   if topic in m:\n",
        "      return m[topic].tolist()\n",
        "   else:\n",
        "      return np.zeros( len(m[list(m.wv.vocab)[0]]) ).tolist()\n",
        "    \n",
        "def encodeSecondColumn( topics ):\n",
        "   if len(topics) == 0:\n",
        "      return np.zeros( len(m[list(m.wv.vocab)[0]]) ).tolist()\n",
        "   topic = topics[0].strip()\n",
        "   if topic in m:\n",
        "      return m[topic].tolist()\n",
        "   else:\n",
        "      return np.zeros( len(m[list(m.wv.vocab)[0]]) ).tolist()\n",
        "    \n",
        "all_data[ 'topic_0' ] = all_data.topics.apply( encodeFirstColumn )\n",
        "all_data[ 'topic_1' ] = all_data.topics.apply( encodeSecondColumn )"
      ],
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1uM8QhQG886",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "d50678a9-613d-4f83-a2b5-34f34ee4c047"
      },
      "source": [
        "all_data.head(2)"
      ],
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>type</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>topics</th>\n",
              "      <th>topic_0</th>\n",
              "      <th>topic_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-10-26</td>\n",
              "      <td>Muslims BUSTED: They Stole Millions In Gov’t B...</td>\n",
              "      <td>Print They should pay all the back all the mon...</td>\n",
              "      <td>0</td>\n",
              "      <td>[print, pay, back, money, plus, interest, enti...</td>\n",
              "      <td>[government , group]</td>\n",
              "      <td>[-1.2580475807189941, -0.871424674987793, -3.3...</td>\n",
              "      <td>[-1.2580475807189941, -0.871424674987793, -3.3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-10-29</td>\n",
              "      <td>Re: Why Did Attorney General Loretta Lynch Ple...</td>\n",
              "      <td>Why Did Attorney General Loretta Lynch Plead T...</td>\n",
              "      <td>0</td>\n",
              "      <td>[attorney, general, loretta, lynch, plead, fif...</td>\n",
              "      <td>[lynch , payment]</td>\n",
              "      <td>[-1.3080602884292603, 0.13403084874153137, 0.2...</td>\n",
              "      <td>[-1.3080602884292603, 0.13403084874153137, 0.2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date  ...                                            topic_1\n",
              "0  2016-10-26  ...  [-1.2580475807189941, -0.871424674987793, -3.3...\n",
              "1  2016-10-29  ...  [-1.3080602884292603, 0.13403084874153137, 0.2...\n",
              "\n",
              "[2 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 280
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8qvjQz5voEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data[ 'date_int' ] = all_data.date.apply( setNumericDate )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YjzryxOHEDx",
        "colab_type": "code",
        "outputId": "03e05965-21f5-4427-a13c-ea0e2ff4d3d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "all_data.head(1)"
      ],
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>type</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>topics</th>\n",
              "      <th>topic_0</th>\n",
              "      <th>topic_1</th>\n",
              "      <th>date_int</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-10-26</td>\n",
              "      <td>Muslims BUSTED: They Stole Millions In Gov’t B...</td>\n",
              "      <td>Print They should pay all the back all the mon...</td>\n",
              "      <td>0</td>\n",
              "      <td>[print, pay, back, money, plus, interest, enti...</td>\n",
              "      <td>[government , group]</td>\n",
              "      <td>[-1.2580475807189941, -0.871424674987793, -3.3...</td>\n",
              "      <td>[-1.2580475807189941, -0.871424674987793, -3.3...</td>\n",
              "      <td>201610</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date  ... date_int\n",
              "0  2016-10-26  ...   201610\n",
              "\n",
              "[1 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 282
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2Aj0rzQwwuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range( vector_dim ):\n",
        "   all_data[str(i)] = all_data.topic_0.apply( lambda x : select(x, i ) )\n",
        "    \n",
        "for i in range( vector_dim ):\n",
        "   all_data[str(vector_dim + i)] = all_data.topic_0.apply( lambda x : select(x, i ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7N75jLuHXmh",
        "colab_type": "code",
        "outputId": "27b16272-4334-4fa1-d943-759acceb6b2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "all_data.head(2)"
      ],
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>type</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>topics</th>\n",
              "      <th>topic_0</th>\n",
              "      <th>topic_1</th>\n",
              "      <th>date_int</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>...</th>\n",
              "      <th>160</th>\n",
              "      <th>161</th>\n",
              "      <th>162</th>\n",
              "      <th>163</th>\n",
              "      <th>164</th>\n",
              "      <th>165</th>\n",
              "      <th>166</th>\n",
              "      <th>167</th>\n",
              "      <th>168</th>\n",
              "      <th>169</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "      <th>180</th>\n",
              "      <th>181</th>\n",
              "      <th>182</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "      <th>188</th>\n",
              "      <th>189</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>193</th>\n",
              "      <th>194</th>\n",
              "      <th>195</th>\n",
              "      <th>196</th>\n",
              "      <th>197</th>\n",
              "      <th>198</th>\n",
              "      <th>199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-10-26</td>\n",
              "      <td>Muslims BUSTED: They Stole Millions In Gov’t B...</td>\n",
              "      <td>Print They should pay all the back all the mon...</td>\n",
              "      <td>0</td>\n",
              "      <td>[print, pay, back, money, plus, interest, enti...</td>\n",
              "      <td>[government , group]</td>\n",
              "      <td>[-1.2580475807189941, -0.871424674987793, -3.3...</td>\n",
              "      <td>[-1.2580475807189941, -0.871424674987793, -3.3...</td>\n",
              "      <td>201610</td>\n",
              "      <td>-1.258048</td>\n",
              "      <td>-0.871425</td>\n",
              "      <td>-3.370791</td>\n",
              "      <td>0.084469</td>\n",
              "      <td>-1.140726</td>\n",
              "      <td>0.782424</td>\n",
              "      <td>0.085001</td>\n",
              "      <td>0.906153</td>\n",
              "      <td>-2.115421</td>\n",
              "      <td>-0.366062</td>\n",
              "      <td>-0.126898</td>\n",
              "      <td>0.980382</td>\n",
              "      <td>1.766235</td>\n",
              "      <td>3.210624</td>\n",
              "      <td>-1.289058</td>\n",
              "      <td>2.41364</td>\n",
              "      <td>2.756452</td>\n",
              "      <td>-0.791824</td>\n",
              "      <td>2.888765</td>\n",
              "      <td>0.382104</td>\n",
              "      <td>3.826663</td>\n",
              "      <td>0.809315</td>\n",
              "      <td>1.665588</td>\n",
              "      <td>3.097708</td>\n",
              "      <td>0.743779</td>\n",
              "      <td>-0.835620</td>\n",
              "      <td>0.202657</td>\n",
              "      <td>-1.956055</td>\n",
              "      <td>1.003207</td>\n",
              "      <td>-0.224625</td>\n",
              "      <td>-0.054840</td>\n",
              "      <td>...</td>\n",
              "      <td>0.820497</td>\n",
              "      <td>-0.177503</td>\n",
              "      <td>0.738038</td>\n",
              "      <td>-0.803803</td>\n",
              "      <td>-0.368957</td>\n",
              "      <td>-2.221324</td>\n",
              "      <td>1.569437</td>\n",
              "      <td>-0.723355</td>\n",
              "      <td>1.589152</td>\n",
              "      <td>-1.386783</td>\n",
              "      <td>1.182975</td>\n",
              "      <td>0.732702</td>\n",
              "      <td>1.323933</td>\n",
              "      <td>-1.039042</td>\n",
              "      <td>3.114866</td>\n",
              "      <td>2.067529</td>\n",
              "      <td>1.860135</td>\n",
              "      <td>-0.212820</td>\n",
              "      <td>-2.872891</td>\n",
              "      <td>-0.884542</td>\n",
              "      <td>1.122983</td>\n",
              "      <td>0.093271</td>\n",
              "      <td>0.588018</td>\n",
              "      <td>1.805188</td>\n",
              "      <td>1.837234</td>\n",
              "      <td>-1.019985</td>\n",
              "      <td>0.00325</td>\n",
              "      <td>-1.684045</td>\n",
              "      <td>-1.749469</td>\n",
              "      <td>-2.838851</td>\n",
              "      <td>1.850891</td>\n",
              "      <td>-1.566991</td>\n",
              "      <td>0.327176</td>\n",
              "      <td>-0.354917</td>\n",
              "      <td>-0.532596</td>\n",
              "      <td>1.564577</td>\n",
              "      <td>0.493866</td>\n",
              "      <td>-1.585111</td>\n",
              "      <td>-2.178654</td>\n",
              "      <td>-0.838643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-10-29</td>\n",
              "      <td>Re: Why Did Attorney General Loretta Lynch Ple...</td>\n",
              "      <td>Why Did Attorney General Loretta Lynch Plead T...</td>\n",
              "      <td>0</td>\n",
              "      <td>[attorney, general, loretta, lynch, plead, fif...</td>\n",
              "      <td>[lynch , payment]</td>\n",
              "      <td>[-1.3080602884292603, 0.13403084874153137, 0.2...</td>\n",
              "      <td>[-1.3080602884292603, 0.13403084874153137, 0.2...</td>\n",
              "      <td>201610</td>\n",
              "      <td>-1.308060</td>\n",
              "      <td>0.134031</td>\n",
              "      <td>0.258583</td>\n",
              "      <td>1.951414</td>\n",
              "      <td>-0.179059</td>\n",
              "      <td>1.896740</td>\n",
              "      <td>1.465460</td>\n",
              "      <td>-0.244400</td>\n",
              "      <td>3.059347</td>\n",
              "      <td>0.628415</td>\n",
              "      <td>-0.722530</td>\n",
              "      <td>-0.889270</td>\n",
              "      <td>2.348423</td>\n",
              "      <td>1.555641</td>\n",
              "      <td>-3.385284</td>\n",
              "      <td>0.58009</td>\n",
              "      <td>0.746505</td>\n",
              "      <td>1.680919</td>\n",
              "      <td>1.575759</td>\n",
              "      <td>-1.477062</td>\n",
              "      <td>-0.716892</td>\n",
              "      <td>-1.748871</td>\n",
              "      <td>-1.507224</td>\n",
              "      <td>0.956061</td>\n",
              "      <td>-3.441853</td>\n",
              "      <td>-1.777627</td>\n",
              "      <td>-0.405750</td>\n",
              "      <td>1.668324</td>\n",
              "      <td>-0.048771</td>\n",
              "      <td>-0.016546</td>\n",
              "      <td>-0.901648</td>\n",
              "      <td>...</td>\n",
              "      <td>1.628752</td>\n",
              "      <td>-0.397067</td>\n",
              "      <td>0.745643</td>\n",
              "      <td>-0.347126</td>\n",
              "      <td>0.240518</td>\n",
              "      <td>-2.491678</td>\n",
              "      <td>-0.026948</td>\n",
              "      <td>0.548095</td>\n",
              "      <td>1.644051</td>\n",
              "      <td>0.282933</td>\n",
              "      <td>0.302674</td>\n",
              "      <td>0.693310</td>\n",
              "      <td>0.691310</td>\n",
              "      <td>-1.720333</td>\n",
              "      <td>-0.500198</td>\n",
              "      <td>-1.695081</td>\n",
              "      <td>-0.152966</td>\n",
              "      <td>-0.081608</td>\n",
              "      <td>0.102699</td>\n",
              "      <td>-0.754797</td>\n",
              "      <td>2.451525</td>\n",
              "      <td>1.637519</td>\n",
              "      <td>2.776080</td>\n",
              "      <td>2.721718</td>\n",
              "      <td>-2.058252</td>\n",
              "      <td>-0.464501</td>\n",
              "      <td>3.03443</td>\n",
              "      <td>1.720201</td>\n",
              "      <td>1.640705</td>\n",
              "      <td>1.319261</td>\n",
              "      <td>0.446005</td>\n",
              "      <td>0.049642</td>\n",
              "      <td>-0.501481</td>\n",
              "      <td>-1.046338</td>\n",
              "      <td>-0.281341</td>\n",
              "      <td>-2.133999</td>\n",
              "      <td>-0.252698</td>\n",
              "      <td>-1.613961</td>\n",
              "      <td>1.189872</td>\n",
              "      <td>-0.158000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 209 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         date  ...       199\n",
              "0  2016-10-26  ... -0.838643\n",
              "1  2016-10-29  ... -0.158000\n",
              "\n",
              "[2 rows x 209 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 284
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSoCBKpCOD57",
        "colab_type": "text"
      },
      "source": [
        "### 9.5 Generating coverage score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41I3GaynODQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keys = [str(i) for i in range(200)]\n",
        "X_Actual = all_data[['date_int'] + keys ]\n",
        "Y_Predict = f_cov.predict(X_Actual)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEElzGLGPcew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data['Coverage'] = Y_Predict "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iSBauwTPtFW",
        "colab_type": "code",
        "outputId": "5201c7eb-61a1-43b2-8448-b2f24d41b662",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sorted(Y_Predict, reverse=True )[:10]"
      ],
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[21, 21, 21, 21, 21, 21, 21, 21, 21, 21]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2w2EU_u45jA",
        "colab_type": "code",
        "outputId": "d7356a61-153b-4d44-ea87-e56a7e4484ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "all_data.type.value_counts()"
      ],
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    51507\n",
              "1    11492\n",
              "Name: type, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 288
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5C-YY4vPm6J",
        "colab_type": "code",
        "outputId": "40470418-fd0b-458f-b93e-7540d179c378",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "all_data.head(2)"
      ],
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>type</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>topics</th>\n",
              "      <th>topic_0</th>\n",
              "      <th>topic_1</th>\n",
              "      <th>date_int</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>...</th>\n",
              "      <th>161</th>\n",
              "      <th>162</th>\n",
              "      <th>163</th>\n",
              "      <th>164</th>\n",
              "      <th>165</th>\n",
              "      <th>166</th>\n",
              "      <th>167</th>\n",
              "      <th>168</th>\n",
              "      <th>169</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "      <th>180</th>\n",
              "      <th>181</th>\n",
              "      <th>182</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "      <th>188</th>\n",
              "      <th>189</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>193</th>\n",
              "      <th>194</th>\n",
              "      <th>195</th>\n",
              "      <th>196</th>\n",
              "      <th>197</th>\n",
              "      <th>198</th>\n",
              "      <th>199</th>\n",
              "      <th>Coverage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-10-26</td>\n",
              "      <td>Muslims BUSTED: They Stole Millions In Gov’t B...</td>\n",
              "      <td>Print They should pay all the back all the mon...</td>\n",
              "      <td>0</td>\n",
              "      <td>[print, pay, back, money, plus, interest, enti...</td>\n",
              "      <td>[government , group]</td>\n",
              "      <td>[-1.2580475807189941, -0.871424674987793, -3.3...</td>\n",
              "      <td>[-1.2580475807189941, -0.871424674987793, -3.3...</td>\n",
              "      <td>201610</td>\n",
              "      <td>-1.258048</td>\n",
              "      <td>-0.871425</td>\n",
              "      <td>-3.370791</td>\n",
              "      <td>0.084469</td>\n",
              "      <td>-1.140726</td>\n",
              "      <td>0.782424</td>\n",
              "      <td>0.085001</td>\n",
              "      <td>0.906153</td>\n",
              "      <td>-2.115421</td>\n",
              "      <td>-0.366062</td>\n",
              "      <td>-0.126898</td>\n",
              "      <td>0.980382</td>\n",
              "      <td>1.766235</td>\n",
              "      <td>3.210624</td>\n",
              "      <td>-1.289058</td>\n",
              "      <td>2.41364</td>\n",
              "      <td>2.756452</td>\n",
              "      <td>-0.791824</td>\n",
              "      <td>2.888765</td>\n",
              "      <td>0.382104</td>\n",
              "      <td>3.826663</td>\n",
              "      <td>0.809315</td>\n",
              "      <td>1.665588</td>\n",
              "      <td>3.097708</td>\n",
              "      <td>0.743779</td>\n",
              "      <td>-0.835620</td>\n",
              "      <td>0.202657</td>\n",
              "      <td>-1.956055</td>\n",
              "      <td>1.003207</td>\n",
              "      <td>-0.224625</td>\n",
              "      <td>-0.054840</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.177503</td>\n",
              "      <td>0.738038</td>\n",
              "      <td>-0.803803</td>\n",
              "      <td>-0.368957</td>\n",
              "      <td>-2.221324</td>\n",
              "      <td>1.569437</td>\n",
              "      <td>-0.723355</td>\n",
              "      <td>1.589152</td>\n",
              "      <td>-1.386783</td>\n",
              "      <td>1.182975</td>\n",
              "      <td>0.732702</td>\n",
              "      <td>1.323933</td>\n",
              "      <td>-1.039042</td>\n",
              "      <td>3.114866</td>\n",
              "      <td>2.067529</td>\n",
              "      <td>1.860135</td>\n",
              "      <td>-0.212820</td>\n",
              "      <td>-2.872891</td>\n",
              "      <td>-0.884542</td>\n",
              "      <td>1.122983</td>\n",
              "      <td>0.093271</td>\n",
              "      <td>0.588018</td>\n",
              "      <td>1.805188</td>\n",
              "      <td>1.837234</td>\n",
              "      <td>-1.019985</td>\n",
              "      <td>0.00325</td>\n",
              "      <td>-1.684045</td>\n",
              "      <td>-1.749469</td>\n",
              "      <td>-2.838851</td>\n",
              "      <td>1.850891</td>\n",
              "      <td>-1.566991</td>\n",
              "      <td>0.327176</td>\n",
              "      <td>-0.354917</td>\n",
              "      <td>-0.532596</td>\n",
              "      <td>1.564577</td>\n",
              "      <td>0.493866</td>\n",
              "      <td>-1.585111</td>\n",
              "      <td>-2.178654</td>\n",
              "      <td>-0.838643</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-10-29</td>\n",
              "      <td>Re: Why Did Attorney General Loretta Lynch Ple...</td>\n",
              "      <td>Why Did Attorney General Loretta Lynch Plead T...</td>\n",
              "      <td>0</td>\n",
              "      <td>[attorney, general, loretta, lynch, plead, fif...</td>\n",
              "      <td>[lynch , payment]</td>\n",
              "      <td>[-1.3080602884292603, 0.13403084874153137, 0.2...</td>\n",
              "      <td>[-1.3080602884292603, 0.13403084874153137, 0.2...</td>\n",
              "      <td>201610</td>\n",
              "      <td>-1.308060</td>\n",
              "      <td>0.134031</td>\n",
              "      <td>0.258583</td>\n",
              "      <td>1.951414</td>\n",
              "      <td>-0.179059</td>\n",
              "      <td>1.896740</td>\n",
              "      <td>1.465460</td>\n",
              "      <td>-0.244400</td>\n",
              "      <td>3.059347</td>\n",
              "      <td>0.628415</td>\n",
              "      <td>-0.722530</td>\n",
              "      <td>-0.889270</td>\n",
              "      <td>2.348423</td>\n",
              "      <td>1.555641</td>\n",
              "      <td>-3.385284</td>\n",
              "      <td>0.58009</td>\n",
              "      <td>0.746505</td>\n",
              "      <td>1.680919</td>\n",
              "      <td>1.575759</td>\n",
              "      <td>-1.477062</td>\n",
              "      <td>-0.716892</td>\n",
              "      <td>-1.748871</td>\n",
              "      <td>-1.507224</td>\n",
              "      <td>0.956061</td>\n",
              "      <td>-3.441853</td>\n",
              "      <td>-1.777627</td>\n",
              "      <td>-0.405750</td>\n",
              "      <td>1.668324</td>\n",
              "      <td>-0.048771</td>\n",
              "      <td>-0.016546</td>\n",
              "      <td>-0.901648</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.397067</td>\n",
              "      <td>0.745643</td>\n",
              "      <td>-0.347126</td>\n",
              "      <td>0.240518</td>\n",
              "      <td>-2.491678</td>\n",
              "      <td>-0.026948</td>\n",
              "      <td>0.548095</td>\n",
              "      <td>1.644051</td>\n",
              "      <td>0.282933</td>\n",
              "      <td>0.302674</td>\n",
              "      <td>0.693310</td>\n",
              "      <td>0.691310</td>\n",
              "      <td>-1.720333</td>\n",
              "      <td>-0.500198</td>\n",
              "      <td>-1.695081</td>\n",
              "      <td>-0.152966</td>\n",
              "      <td>-0.081608</td>\n",
              "      <td>0.102699</td>\n",
              "      <td>-0.754797</td>\n",
              "      <td>2.451525</td>\n",
              "      <td>1.637519</td>\n",
              "      <td>2.776080</td>\n",
              "      <td>2.721718</td>\n",
              "      <td>-2.058252</td>\n",
              "      <td>-0.464501</td>\n",
              "      <td>3.03443</td>\n",
              "      <td>1.720201</td>\n",
              "      <td>1.640705</td>\n",
              "      <td>1.319261</td>\n",
              "      <td>0.446005</td>\n",
              "      <td>0.049642</td>\n",
              "      <td>-0.501481</td>\n",
              "      <td>-1.046338</td>\n",
              "      <td>-0.281341</td>\n",
              "      <td>-2.133999</td>\n",
              "      <td>-0.252698</td>\n",
              "      <td>-1.613961</td>\n",
              "      <td>1.189872</td>\n",
              "      <td>-0.158000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 210 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         date  ... Coverage\n",
              "0  2016-10-26  ...        0\n",
              "1  2016-10-29  ...        0\n",
              "\n",
              "[2 rows x 210 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 289
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmhUTyQSQdrD",
        "colab_type": "text"
      },
      "source": [
        "### 9.6 Exporting csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDU7r-jeQfdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data_to_export = all_data[[\"title\", \"Coverage\"]]\n",
        "all_data_to_export.to_csv('all_data_coverage_condensed.csv', index=False )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8ANQnadYPry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('all_data_coverage_condensed.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmFpmsBReluz",
        "colab_type": "text"
      },
      "source": [
        "### 9.7 Plotting results for visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXdP1JmmfaSp",
        "colab_type": "code",
        "outputId": "44e09a40-e560-4bfd-ee23-a8a79e58a0de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "bins = range(10)\n",
        "plt.hist(all_data.Coverage, bins, histtype='bar', rwidth=0.8, cumulative=False )\n",
        "plt.xlabel( \"Coverage Score\" )\n",
        "plt.ylabel( \"Count\")"
      ],
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Count')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 302
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp0uOhGEnKmj",
        "colab_type": "code",
        "outputId": "ca5e7045-1cbd-4850-a4d2-80748dd7e4d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "plt.scatter(all_data.date_int, all_data.Coverage )\n",
        "plt.xlabel( \"Date (Integer/Concatenated Form)\" )\n",
        "plt.ylabel( \"Coverage Score\" )"
      ],
      "execution_count": 296,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Coverage Score')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 296
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdXbya-ulkvZ",
        "colab_type": "text"
      },
      "source": [
        "<h2>9 Works Cited</h2>\n",
        "\n",
        "Arsanjani, A. (2018, November 18). Notes : [Notes under #weekly-notes on slack]. Retrieved November 20, 2018. \n",
        "\n",
        "Classifier comparison¶. (n.d.). Retrieved November 20, 2018, from https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html \n",
        "\n",
        "Eight, F. (2016, November 20). Political Social Media Posts. Retrieved November 20, 2018, from https://www.kaggle.com/crowdflower/political-social-media-posts \n",
        "\n",
        "Li, S. (2018, May 31). Topic Modeling and Latent Dirichlet Allocation (LDA) in Python. Retrieved November 20, 2018, from https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24\n",
        "\n",
        "Martin, B., & Koufos, N. (n.d.). Sentiment Analysis on Reddit News Headlines with Python's Natural Language Toolkit (NLTK). Retrieved December 8, 2018, from https://www.learndatasci.com/tutorials/sentiment-analysis-reddit-headlines-pythons-nltk/\n",
        "\n",
        "News API. (n.d.). News API - A JSON API for live news and blog articles. Retrieved November 20, 2018, from https://newsapi.org/ \n",
        "\n",
        "Risdal, M. (2016, November 25). Getting Real about Fake News. Retrieved November 20, 2018, from https://www.kaggle.com/mrisdal/fake-news \n",
        "\n",
        "Shu, K., Sliva, A., Wang, S., Tang, J., & Liu, H. (2017). Fake News Detection on Social Media. ACM SIGKDD Explorations Newsletter, 19(1), 22-36. doi:10.1145/3137597.3137600 \n",
        "\n",
        "Thompson, A. (2017, August 20). All the news. Retrieved November 20, 2018, from https://www.kaggle.com/snapcrack/all-the-news \n",
        "\n",
        "Rehurek, R. (2018, September 20). Gensim: Topic modelling for humans. Retrieved December 4, 2018, from https://radimrehurek.com/gensim/models/doc2vec.html\n",
        "\n",
        "Budhiraja, A. (2018, May 14). A simple explanation of document embeddings generated using Doc2Vec. Retrieved December 4, 2018, from https://medium.com/@amarbudhiraja/understanding-document-embeddings-of-doc2vec-bfe7237a26da\n",
        "\n",
        "Rachuta, K. (2016, May 27). Importing and exporting CSV files in Python – Kasia Rachuta – Medium. Retrieved December 9, 2018, from https://medium.com/@kasiarachuta/importing-and-exporting-csv-files-in-python-7fa6e4d9f408\n",
        "\n",
        "RaRe-Technologies. (2018, October 4). RaRe-Technologies/gensim. Retrieved December 4, 2018, from https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/doc2vec.py\n",
        "\n",
        "<h2> 10 Image Credits</h2>\n",
        "\n",
        "Pixabay. (n.d.). Newspaper Lot. Retrieved November 20, 2018, from https://www.pexels.com/photo/administration-articles-bank-black-and-white-261949/ \n",
        "\n",
        "Rawpixel.com. (n.d.). Person Reading the Daily Fake News Newspaper Sitting on Gray Couch. Retrieved November 20, 2018, from https://www.pexels.com/photo/person-reading-the-daily-fake-news-newspaper-sitting-on-gray-couch-1327218/ \n"
      ]
    }
  ]
}